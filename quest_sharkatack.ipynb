{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/camilla-scandola/project-shark-attack/blob/main/quest_sharkatack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEzYg3TCIR4L",
    "outputId": "403583b3-1382-4d2b-ba8b-46ec8f49d2ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YncNJ57OIbev",
    "outputId": "2d247253-d2c9-44c9-e750-ec09bd3d3c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/anaconda3/lib/python3.13/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/lib/python3.13/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJx1JH0XIkrR",
    "outputId": "507f77eb-e5c9-4f42-cd12-bbbb03dd7429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /opt/anaconda3/lib/python3.13/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [

      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AdlQ0fITIp6Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PGVDRxp072hj"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('GSAF5.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "dM138EG4K6ze",
    "outputId": "d15da878-a006-454a-a7d9-e4d4fb9a2aa5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16th August 2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Cayo Costa Boca Grande</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Shawn Meuse</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Laceration to right leg below the knee</td>\n",
       "      <td>N</td>\n",
       "      <td>1055 hrs</td>\n",
       "      <td>Lemon shark 1.8 m (6ft)</td>\n",
       "      <td>Johannes Marchand: Kevin McMurray Trackingshar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Brad Ross</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>None sustained board severly damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>0730hrs</td>\n",
       "      <td>5m (16.5ft) Great White</td>\n",
       "      <td>Bob Myatt GSAF The Guardian: 9 News: ABS News:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>Severe injuries no detail</td>\n",
       "      <td>N</td>\n",
       "      <td>1300hrs</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Ralph Collier GSAF and Kevin MCMurray Tracking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Tathra Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bowie Daley</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>None sustained board severely damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>1630hrs</td>\n",
       "      <td>Suspected Great White</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Carolina Beach</td>\n",
       "      <td>Wading</td>\n",
       "      <td>Eleonora Boi</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Bite to thigh area</td>\n",
       "      <td>N</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Kevin McMurray Trackingsharks.com: NY Post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Year        Type      Country  \\\n",
       "0  16th August 2025  2025.0    Provoked          USA   \n",
       "1       18th August  2025.0  Unprovoked    Australia   \n",
       "2       17th August  2025.0  Unprovoked      Bahamas   \n",
       "3        7th August  2025.0  Unprovoked    Australia   \n",
       "4        1st August  2025.0  Unprovoked  Puerto Rico   \n",
       "\n",
       "                               State                             Location  \\\n",
       "0                            Florida               Cayo Costa Boca Grande   \n",
       "1                                NSW                       Cabarita Beach   \n",
       "2  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "3                                NSW                        Tathra Beach    \n",
       "4                           Carolina                       Carolina Beach   \n",
       "\n",
       "       Activity          Name Sex Age                                  Injury  \\\n",
       "0       Fishing   Shawn Meuse   M   ?  Laceration to right leg below the knee   \n",
       "1       Surfing     Brad Ross   M   ?    None sustained board severly damaged   \n",
       "2  Spearfishing    Not stated   M  63               Severe injuries no detail   \n",
       "3       Surfing   Bowie Daley   M   9   None sustained board severely damaged   \n",
       "4        Wading  Eleonora Boi   F  39                      Bite to thigh area   \n",
       "\n",
       "  Fatal Y/N        Time                 Species   \\\n",
       "0         N    1055 hrs  Lemon shark 1.8 m (6ft)   \n",
       "1         N     0730hrs  5m (16.5ft) Great White   \n",
       "2         N     1300hrs             Undetermined   \n",
       "3         N     1630hrs    Suspected Great White   \n",
       "4         N  Not stated             Undetermined   \n",
       "\n",
       "                                              Source  pdf href formula href  \\\n",
       "0  Johannes Marchand: Kevin McMurray Trackingshar...  NaN          NaN  NaN   \n",
       "1  Bob Myatt GSAF The Guardian: 9 News: ABS News:...  NaN          NaN  NaN   \n",
       "2  Ralph Collier GSAF and Kevin MCMurray Tracking...  NaN          NaN  NaN   \n",
       "3                                     Bob Myatt GSAF  NaN          NaN  NaN   \n",
       "4         Kevin McMurray Trackingsharks.com: NY Post  NaN          NaN  NaN   \n",
       "\n",
       "  Case Number Case Number.1  original order Unnamed: 21 Unnamed: 22  \n",
       "0         NaN           NaN             NaN         NaN         NaN  \n",
       "1         NaN           NaN             NaN         NaN         NaN  \n",
       "2         NaN           NaN             NaN         NaN         NaN  \n",
       "3         NaN           NaN             NaN         NaN         NaN  \n",
       "4         NaN           NaN             NaN         NaN         NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete empty columns\n",
    "df = df.drop(columns=[col for col in [\"pdf\", \"href formula\", \"href\", \"Case Number\", \"Case Number.1\", \"original order\", \"Unnamed: 21\", \"Unnamed: 22\"] if col in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started analyzing the dataset by country, state, and location, since the first two play a key role in understanding the overall risks of surfing worldwide. For the country column, only 50 entries are missing out of a 7,041 total, so these rows can be dropped without affecting the analysis.\n",
    "For state and location, however, the number of missing values is much higher. Instead of dropping them (which would remove too much data), I will replace missing entries with \"undefined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TAMzlrC176A2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing country values: 50\n",
      "Missing state values: 485\n",
      "Missing location values: 567\n",
      "(7042, 15)\n"
     ]
    }
   ],
   "source": [
    "#overview of missing values by country, state, location\n",
    "\n",
    "missing_country = int(df['Country'].isna().sum())\n",
    "print(f\"Missing country values: {missing_country}\")\n",
    "\n",
    "missing_state = int(df['State'].isna().sum())\n",
    "print(f\"Missing state values: {missing_state}\")\n",
    "\n",
    "missing_location = int(df['Location'].isna().sum())\n",
    "print(f\"Missing location values: {missing_location}\")\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "#suggestion: drop all the null values under country (because they won't make a big difference in the analysis, being 50 out of 7041)\n",
    "df = df.dropna(subset=['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suggestion: the number of missing values in states and locations is a lot more significant, so I'd replace them with undefined for the time being\n",
    "df['State'] = df['State'].fillna('undefined')\n",
    "df['Location'] = df['Location'].fillna('undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country_cleaned\n",
      "Usa                                      2570\n",
      "Australia                                1507\n",
      "South Africa                              599\n",
      "New Zealand                               146\n",
      "Bahamas                                   141\n",
      "Papua New Guinea                          136\n",
      "Brazil                                    122\n",
      "Mexico                                    107\n",
      "Italy                                      72\n",
      "Fiji                                       70\n",
      "New Caledonia                              66\n",
      "Philippines                                65\n",
      "Reunion                                    60\n",
      "Egypt                                      53\n",
      "Mozambique                                 50\n",
      "Cuba                                       49\n",
      "Spain                                      47\n",
      "India                                      41\n",
      "French Polynesia                           39\n",
      "Japan                                      36\n",
      "Croatia                                    35\n",
      "Panama                                     32\n",
      "Jamaica                                    32\n",
      "Solomon Islands                            30\n",
      "Iran                                       29\n",
      "England                                    25\n",
      "Indonesia                                  25\n",
      "Hong Kong                                  24\n",
      "Greece                                     24\n",
      "Pacific Ocean                              19\n",
      "Tonga                                      18\n",
      "Costa Rica                                 18\n",
      "Atlantic Ocean                             17\n",
      "Bermuda                                    16\n",
      "Vanuatu                                    15\n",
      "Vietnam                                    15\n",
      "Canada                                     14\n",
      "Sri Lanka                                  14\n",
      "Marshall Islands                           13\n",
      "Thailand                                   13\n",
      "France                                     13\n",
      "Turkey                                     12\n",
      "Iraq                                       12\n",
      "South Atlantic Ocean                       12\n",
      "Ecuador                                    11\n",
      "United Kingdom                             11\n",
      "Senegal                                    11\n",
      "Venezuela                                  11\n",
      "Seychelles                                 10\n",
      "Mauritius                                  10\n",
      "Columbia                                   10\n",
      "Kenya                                      10\n",
      "Samoa                                      10\n",
      "New Guinea                                 10\n",
      "Taiwan                                      9\n",
      "Sierra Leone                                9\n",
      "China                                       9\n",
      "Israel                                      9\n",
      "Yemen                                       9\n",
      "South Korea                                 8\n",
      "Belize                                      8\n",
      "Caribbean Sea                               8\n",
      "Scotland                                    8\n",
      "Madagascar                                  8\n",
      "Tanzania                                    8\n",
      "Chile                                       8\n",
      "North Pacific Ocean                         7\n",
      "Dominican Republic                          7\n",
      "Indian Ocean                                7\n",
      "Nicaragua                                   7\n",
      "Barbados                                    6\n",
      "Honduras                                    6\n",
      "Kiribati                                    6\n",
      "Okinawa                                     6\n",
      "Somalia                                     6\n",
      "Maldives                                    6\n",
      "Singapore                                   6\n",
      "New Britain                                 6\n",
      "Libya                                       6\n",
      "Turks & Caicos                              5\n",
      "Azores                                      5\n",
      "Malta                                       5\n",
      "North Atlantic Ocean                        5\n",
      "Saudi Arabia                                5\n",
      "Malaysia                                    5\n",
      "Palau                                       5\n",
      "Reunion Island                              5\n",
      "Mid Atlantic Ocean                          5\n",
      "Burma                                       4\n",
      "El Salvador                                 4\n",
      "Persian Gulf                                4\n",
      "Sudan                                       4\n",
      "Grenada                                     4\n",
      "Uruguay                                     4\n",
      "Russia                                      4\n",
      "Nigeria                                     4\n",
      "Guam                                        4\n",
      "Portugal                                    4\n",
      "Ceylon                                      3\n",
      "Turks And Caicos                            3\n",
      "Tunisia                                     3\n",
      "Maldive Islands                             3\n",
      "Montenegro                                  3\n",
      "Cape Verde                                  3\n",
      "Haiti                                       3\n",
      "Guyana                                      3\n",
      "Trinidad & Tobago                           3\n",
      "Martinique                                  3\n",
      "Micronesia                                  3\n",
      "Liberia                                     3\n",
      "Guinea                                      3\n",
      "American Samoa                              3\n",
      "Lebanon                                     3\n",
      "Tobago                                      3\n",
      "Argentina                                   2\n",
      "Johnston Island                             2\n",
      "South Pacific Ocean                         2\n",
      "Puerto Rico                                 2\n",
      "West Indies                                 2\n",
      "Peru                                        2\n",
      "Crete                                       2\n",
      "Ireland                                     2\n",
      "Colombia                                    2\n",
      "Iceland                                     2\n",
      "St Helena, British Overseas Territory       2\n",
      "United Arab Emirates                        2\n",
      "Norway                                      2\n",
      "Cayman Islands                              2\n",
      "Mediterranean Sea                           2\n",
      "Java                                        2\n",
      "Central Pacific                             2\n",
      "Namibia                                     2\n",
      "Southwest Pacific Ocean                     2\n",
      "United Arab Emirates (Uae)                  2\n",
      "Antigua                                     2\n",
      "Italy / Croatia                             1\n",
      "British New Guinea                          1\n",
      "Paraguay                                    1\n",
      "Monaco                                      1\n",
      "Canary Islands                              1\n",
      "Cyprus                                      1\n",
      "San Domingo                                 1\n",
      "Falkland Islands                            1\n",
      "Kuwait                                      1\n",
      "Nevis                                       1\n",
      "Ocean                                       1\n",
      "Ghana                                       1\n",
      "Asia?                                       1\n",
      "Red Sea?                                    1\n",
      "Korea                                       1\n",
      "Bahrein                                     1\n",
      "Djibouti                                    1\n",
      "Between Portugal & India                    1\n",
      "Roatan                                      1\n",
      "Sweden                                      1\n",
      "Greenland                                   1\n",
      "Tasman Sea                                  1\n",
      "Georgia                                     1\n",
      "Coast Of Africa                             1\n",
      "Algeria                                     1\n",
      "Africa                                      1\n",
      "Cook Islands                                1\n",
      "Equatorial Guinea / Cameroon                1\n",
      "Curacao                                     1\n",
      "Indian Ocean?                               1\n",
      "Tuvalu                                      1\n",
      "Syria                                       1\n",
      "Andaman Islands                             1\n",
      "The Balkans                                 1\n",
      "Slovenia                                    1\n",
      "Angola                                      1\n",
      "Jordan                                      1\n",
      "St Kitts / Nevis                            1\n",
      "British Isles                               1\n",
      "St Martin                                   1\n",
      "Western Samoa                               1\n",
      "Bangladesh                                  1\n",
      "South China Sea                             1\n",
      "Comoros                                     1\n",
      "Northern Arabian Sea                        1\n",
      "Coral Sea                                   1\n",
      "Egypt / Israel                              1\n",
      "Aruba                                       1\n",
      "St. Martin                                  1\n",
      "Diego Garcia                                1\n",
      "Palestinian Territories                     1\n",
      "Grand Cayman                                1\n",
      "St. Maartin                                 1\n",
      "Gulf Of Aden                                1\n",
      "British Overseas Territory                  1\n",
      "Red Sea                                     1\n",
      "Mid-Pacifc Ocean                            1\n",
      "Mayotte                                     1\n",
      "Bay Of Bengal                               1\n",
      "Solomon Islands / Vanuatu                   1\n",
      "Iran / Iraq                                 1\n",
      "Northern Mariana Islands                    1\n",
      "Netherlands Antilles                        1\n",
      "Guatemala                                   1\n",
      "Sudan?                                      1\n",
      "British Virgin Islands                      1\n",
      "Gabon                                       1\n",
      "Trinidad                                    1\n",
      "Andaman / Nicobar Islandas                  1\n",
      "Hawaii                                      1\n",
      "North Sea                                   1\n",
      "Red Sea / Indian Ocean                      1\n",
      "Morocco                                     1\n",
      "British West Indies                         1\n",
      "Admiralty Islands                           1\n",
      "Federated States Of Micronesia              1\n",
      "Ceylon (Sri Lanka)                          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#imported pycountry to filter out all entries that do not correspond to standard countries\n",
    "\n",
    "import pycountry\n",
    "\n",
    "#cleaning format of Country column by removing any puntuation, extra spaces, and fixing lower-case and capitalization\n",
    "\n",
    "df['Country_cleaned'] = df['Country'].astype(str).str.strip().str.lower().str.title().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    \n",
    "    print(df['Country_cleaned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country_cleaned\n",
       "Pacific Ocean                            19\n",
       "Atlantic Ocean                           17\n",
       "South Atlantic Ocean                     12\n",
       "Caribbean Sea                             8\n",
       "Indian Ocean                              7\n",
       "North Pacific Ocean                       7\n",
       "Mid Atlantic Ocean                        5\n",
       "North Atlantic Ocean                      5\n",
       "St Helena, British Overseas Territory     2\n",
       "Mediterranean Sea                         2\n",
       "South Pacific Ocean                       2\n",
       "Southwest Pacific Ocean                   2\n",
       "Tasman Sea                                1\n",
       "Indian Ocean?                             1\n",
       "Ocean                                     1\n",
       "Mid-Pacifc Ocean                          1\n",
       "Coral Sea                                 1\n",
       "North Sea                                 1\n",
       "Red Sea / Indian Ocean                    1\n",
       "British Overseas Territory                1\n",
       "Red Sea                                   1\n",
       "South China Sea                           1\n",
       "Northern Arabian Sea                      1\n",
       "Red Sea?                                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Country_cleaned'].str.contains('sea|ocean', case=False, na=False)]['Country_cleaned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_cleaned</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Coral Sea</td>\n",
       "      <td>On a round-the-world expedition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>British Overseas Territory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>St Helena, British Overseas Territory</td>\n",
       "      <td>Surfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>St Helena, British Overseas Territory</td>\n",
       "      <td>Snorkeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Transatlantic Rowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Competing in the Woodvale Atlantic Rowing Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Competing in the Woodvale Atlantic Rowing Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Competing in the Woodvale Atlantic Rowing Race</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td>Sinking of the 40' Esperanza off St. Maartin w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3043</th>\n",
       "      <td>Northern Arabian Sea</td>\n",
       "      <td>Fell off aircraft carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>North Atlantic Ocean</td>\n",
       "      <td>Gaffing netted shark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>South China Sea</td>\n",
       "      <td>Diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4326</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Hauling dead shark aboard, when another shark ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4346</th>\n",
       "      <td>South Pacific Ocean</td>\n",
       "      <td>Treading water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>Red Sea</td>\n",
       "      <td>Standing in waist-deep water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Greek steamship Lakonia caught fire, 98 of her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>North Pacific Ocean</td>\n",
       "      <td>Fishing for sharks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>Mid Atlantic Ocean</td>\n",
       "      <td>Abandoning burning ship Captain George in ragi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4516</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>When  a deckhand  jumped overboard, McIver div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>Mid Atlantic Ocean</td>\n",
       "      <td>Survived US Naval aircraft crash, climbing onb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>North Pacific Ocean</td>\n",
       "      <td>Free diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4654</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Pacific Seafarer of US Navy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>Red Sea / Indian Ocean</td>\n",
       "      <td>Cargo ship El Gamil entroute Suez to Yemen (Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>R5D aircraft went down with 29 on board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>North Sea</td>\n",
       "      <td>Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td>Aircraft crashed into sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td>Columbian petrol barge Rio Atrato burned and sank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>North Atlantic Ocean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>Mid Atlantic Ocean</td>\n",
       "      <td>Jumped overboard to rescue a man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Paddling &amp; sailing from Buenos Aires to Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>U.S. Airforce C124 enroute from Hickham Air Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>U.S. Airforce C124 enroute from Hickham Air Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Air/Sea Disaster Pan-American Airlines Stratoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>Mid Atlantic Ocean</td>\n",
       "      <td>Air/Sea Disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>North Pacific Ocean</td>\n",
       "      <td>\"Flying Tiger\" transport plane went down with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>North Pacific Ocean</td>\n",
       "      <td>\"Flying Tiger\" transport plane went down with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>North Atlantic Ocean</td>\n",
       "      <td>Treading water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5100</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Royal Hawaiian skymaster DC-6B aircraft went d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>Adrift on a 4'  raft for 32 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5159</th>\n",
       "      <td>North Atlantic Ocean</td>\n",
       "      <td>cargo ship Southern Isle sank at 04h00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Fell overboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>North Pacific Ocean</td>\n",
       "      <td>Air/Sea Disaster involving C-54 Air Force Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>Mid Atlantic Ocean</td>\n",
       "      <td>Leicester abandoned in a hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Moving shark from tuna vessel when boat rolled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5369</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td>Fell overboard from US Navy PC boat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5372</th>\n",
       "      <td>North Pacific Ocean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>South Pacific Ocean</td>\n",
       "      <td>Adrift on raft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5392</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>The 6711-ton American freighter &amp; troop transp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>B-24 crashed during a search mission. Survivor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>ship torpedoed 400 miles off the African coas....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>The USS Wahoo torpedoes &amp; sank the Japanese tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>On 6-Nov-1942, the German submarine U-68 sank ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>In rubber dinghy with Captain Eddie Rickenback...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>The 6015-ton British ship Empire Avocet was to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>The Pacquebot Laconia, enroute to Liverpool wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>Southwest Pacific Ocean</td>\n",
       "      <td>Adrift on life raft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>The SS Potlach was torpedoed &amp; sunk by the U-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>H.M.S. Cornwall &amp; H.M.S.Dorsetshire sunk by Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>Mid-Pacifc Ocean</td>\n",
       "      <td>Plane forced down, 3 men on rubber life raft. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>Southwest Pacific Ocean</td>\n",
       "      <td>Ditched plane in the sea &amp; were adrift on a ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>Torpedoed &amp; burning British  light cruiser wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>HMAS Parramatta torpedoed &amp; sunk by the U-559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>HMAS Parramatta torpedoed &amp; sunk by the U-559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5462</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>British cruiser Dunedin torpedoed &amp; sunk by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td>SS Ethel Skakel foundered in Central America H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Ditched aircraft, 3 men in the water. Swam for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>The troopship Britannia was sunk by the German...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5476</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>Rescuing seaman after ship sunk by German raider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5477</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Adrift on raft after their ship was sunk by an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Japanese freighter Bokuyo Maru burned &amp; sank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>Fell overboard from SS Ripley Castle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6042</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Jumped overboard from Norwegian steamship Venator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>North Atlantic Ocean</td>\n",
       "      <td>Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>Fell overboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>Swimming after falling overboard from the seal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Fell overboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>a canoe was pursuing a schooner that had forc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Thrown overboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6451</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>Swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>Ocean</td>\n",
       "      <td>British ship Macedon was thrown on her beam en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6497</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Fell or jumped overboard from the liner Rhynland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6520</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Fell overboard from the Selim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>Boat with 5 men capsized while returning to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>Boat with 5 men capsized while returning to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6625</th>\n",
       "      <td>Indian Ocean?</td>\n",
       "      <td>Swimming to avoid capture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>South Atlantic Ocean</td>\n",
       "      <td>Adrift on a raft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>Fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6750</th>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>Tasman Sea</td>\n",
       "      <td>Hooking into a whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6826</th>\n",
       "      <td>Caribbean Sea</td>\n",
       "      <td>Wreck of the schooner Driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6881</th>\n",
       "      <td>Mediterranean Sea</td>\n",
       "      <td>Fell overboard from a frigate &amp; was swallowed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>Red Sea?</td>\n",
       "      <td>Free diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>Mediterranean Sea</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>North Pacific Ocean</td>\n",
       "      <td>Fishing, wading with string of fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Country_cleaned  \\\n",
       "134                               Coral Sea   \n",
       "329              British Overseas Territory   \n",
       "817   St Helena, British Overseas Territory   \n",
       "858   St Helena, British Overseas Territory   \n",
       "1158                         Atlantic Ocean   \n",
       "2218                         Atlantic Ocean   \n",
       "2220                         Atlantic Ocean   \n",
       "2229                         Atlantic Ocean   \n",
       "2685                          Caribbean Sea   \n",
       "3043                   Northern Arabian Sea   \n",
       "3224                          Caribbean Sea   \n",
       "3798                   North Atlantic Ocean   \n",
       "3804                        South China Sea   \n",
       "4059                          Pacific Ocean   \n",
       "4296                          Caribbean Sea   \n",
       "4326                          Pacific Ocean   \n",
       "4346                    South Pacific Ocean   \n",
       "4369                                Red Sea   \n",
       "4443                         Atlantic Ocean   \n",
       "4460                    North Pacific Ocean   \n",
       "4507                     Mid Atlantic Ocean   \n",
       "4516                   South Atlantic Ocean   \n",
       "4602                     Mid Atlantic Ocean   \n",
       "4640                    North Pacific Ocean   \n",
       "4654                         Atlantic Ocean   \n",
       "4681                 Red Sea / Indian Ocean   \n",
       "4686                          Pacific Ocean   \n",
       "4708                              North Sea   \n",
       "4750                          Caribbean Sea   \n",
       "4809                          Caribbean Sea   \n",
       "4811                   North Atlantic Ocean   \n",
       "4821                     Mid Atlantic Ocean   \n",
       "4846                         Atlantic Ocean   \n",
       "4874                          Pacific Ocean   \n",
       "4875                          Pacific Ocean   \n",
       "4911                          Pacific Ocean   \n",
       "4976                     Mid Atlantic Ocean   \n",
       "5002                    North Pacific Ocean   \n",
       "5003                    North Pacific Ocean   \n",
       "5012                   North Atlantic Ocean   \n",
       "5100                          Pacific Ocean   \n",
       "5111                           Indian Ocean   \n",
       "5159                   North Atlantic Ocean   \n",
       "5168                          Pacific Ocean   \n",
       "5261                    North Pacific Ocean   \n",
       "5267                     Mid Atlantic Ocean   \n",
       "5308                          Pacific Ocean   \n",
       "5369                          Caribbean Sea   \n",
       "5372                    North Pacific Ocean   \n",
       "5386                    South Pacific Ocean   \n",
       "5392                          Pacific Ocean   \n",
       "5400                          Pacific Ocean   \n",
       "5404                           Indian Ocean   \n",
       "5410                          Pacific Ocean   \n",
       "5421                           Indian Ocean   \n",
       "5426                          Pacific Ocean   \n",
       "5429                         Atlantic Ocean   \n",
       "5430                         Atlantic Ocean   \n",
       "5432                Southwest Pacific Ocean   \n",
       "5434                         Atlantic Ocean   \n",
       "5441                           Indian Ocean   \n",
       "5454                       Mid-Pacifc Ocean   \n",
       "5455                Southwest Pacific Ocean   \n",
       "5458                   South Atlantic Ocean   \n",
       "5460                   South Atlantic Ocean   \n",
       "5461                   South Atlantic Ocean   \n",
       "5462                   South Atlantic Ocean   \n",
       "5464                          Caribbean Sea   \n",
       "5471                          Pacific Ocean   \n",
       "5472                   South Atlantic Ocean   \n",
       "5476                   South Atlantic Ocean   \n",
       "5477                         Atlantic Ocean   \n",
       "5520                          Pacific Ocean   \n",
       "5879                   South Atlantic Ocean   \n",
       "6042                         Atlantic Ocean   \n",
       "6127                   North Atlantic Ocean   \n",
       "6233                           Indian Ocean   \n",
       "6399                   South Atlantic Ocean   \n",
       "6405                         Atlantic Ocean   \n",
       "6413                          Pacific Ocean   \n",
       "6427                         Atlantic Ocean   \n",
       "6451                           Indian Ocean   \n",
       "6478                                  Ocean   \n",
       "6497                         Atlantic Ocean   \n",
       "6520                          Pacific Ocean   \n",
       "6533                         Atlantic Ocean   \n",
       "6572                   South Atlantic Ocean   \n",
       "6573                   South Atlantic Ocean   \n",
       "6585                           Indian Ocean   \n",
       "6625                          Indian Ocean?   \n",
       "6632                   South Atlantic Ocean   \n",
       "6746                          Pacific Ocean   \n",
       "6750                         Atlantic Ocean   \n",
       "6814                             Tasman Sea   \n",
       "6826                          Caribbean Sea   \n",
       "6881                      Mediterranean Sea   \n",
       "6968                               Red Sea?   \n",
       "6974                      Mediterranean Sea   \n",
       "6997                    North Pacific Ocean   \n",
       "7009                          Pacific Ocean   \n",
       "\n",
       "                                               Activity  \n",
       "134                     On a round-the-world expedition  \n",
       "329                                                 NaN  \n",
       "817                                             Surfing  \n",
       "858                                          Snorkeling  \n",
       "1158                               Transatlantic Rowing  \n",
       "2218     Competing in the Woodvale Atlantic Rowing Race  \n",
       "2220     Competing in the Woodvale Atlantic Rowing Race  \n",
       "2229     Competing in the Woodvale Atlantic Rowing Race  \n",
       "2685  Sinking of the 40' Esperanza off St. Maartin w...  \n",
       "3043                          Fell off aircraft carrier  \n",
       "3224                                                     \n",
       "3798                               Gaffing netted shark  \n",
       "3804                                             Diving  \n",
       "4059                                            Fishing  \n",
       "4296                                                NaN  \n",
       "4326  Hauling dead shark aboard, when another shark ...  \n",
       "4346                                     Treading water  \n",
       "4369                       Standing in waist-deep water  \n",
       "4443  Greek steamship Lakonia caught fire, 98 of her...  \n",
       "4460                                 Fishing for sharks  \n",
       "4507  Abandoning burning ship Captain George in ragi...  \n",
       "4516  When  a deckhand  jumped overboard, McIver div...  \n",
       "4602  Survived US Naval aircraft crash, climbing onb...  \n",
       "4640                                        Free diving  \n",
       "4654                        Pacific Seafarer of US Navy  \n",
       "4681  Cargo ship El Gamil entroute Suez to Yemen (Ad...  \n",
       "4686            R5D aircraft went down with 29 on board  \n",
       "4708                                            Fishing  \n",
       "4750                          Aircraft crashed into sea  \n",
       "4809  Columbian petrol barge Rio Atrato burned and sank  \n",
       "4811                                                NaN  \n",
       "4821                   Jumped overboard to rescue a man  \n",
       "4846      Paddling & sailing from Buenos Aires to Miami  \n",
       "4874  U.S. Airforce C124 enroute from Hickham Air Ba...  \n",
       "4875  U.S. Airforce C124 enroute from Hickham Air Ba...  \n",
       "4911  Air/Sea Disaster Pan-American Airlines Stratoc...  \n",
       "4976                                   Air/Sea Disaster  \n",
       "5002  \"Flying Tiger\" transport plane went down with ...  \n",
       "5003  \"Flying Tiger\" transport plane went down with ...  \n",
       "5012                                     Treading water  \n",
       "5100  Royal Hawaiian skymaster DC-6B aircraft went d...  \n",
       "5111                   Adrift on a 4'  raft for 32 days  \n",
       "5159             cargo ship Southern Isle sank at 04h00  \n",
       "5168                                     Fell overboard  \n",
       "5261  Air/Sea Disaster involving C-54 Air Force Tran...  \n",
       "5267                 Leicester abandoned in a hurricane  \n",
       "5308  Moving shark from tuna vessel when boat rolled...  \n",
       "5369                Fell overboard from US Navy PC boat  \n",
       "5372                                                NaN  \n",
       "5386                                     Adrift on raft  \n",
       "5392  The 6711-ton American freighter & troop transp...  \n",
       "5400  B-24 crashed during a search mission. Survivor...  \n",
       "5404  ship torpedoed 400 miles off the African coas....  \n",
       "5410  The USS Wahoo torpedoes & sank the Japanese tr...  \n",
       "5421  On 6-Nov-1942, the German submarine U-68 sank ...  \n",
       "5426  In rubber dinghy with Captain Eddie Rickenback...  \n",
       "5429  The 6015-ton British ship Empire Avocet was to...  \n",
       "5430  The Pacquebot Laconia, enroute to Liverpool wi...  \n",
       "5432                                Adrift on life raft  \n",
       "5434  The SS Potlach was torpedoed & sunk by the U-1...  \n",
       "5441  H.M.S. Cornwall & H.M.S.Dorsetshire sunk by Ja...  \n",
       "5454  Plane forced down, 3 men on rubber life raft. ...  \n",
       "5455  Ditched plane in the sea & were adrift on a ru...  \n",
       "5458  Torpedoed & burning British  light cruiser wit...  \n",
       "5460      HMAS Parramatta torpedoed & sunk by the U-559  \n",
       "5461      HMAS Parramatta torpedoed & sunk by the U-559  \n",
       "5462  British cruiser Dunedin torpedoed & sunk by th...  \n",
       "5464  SS Ethel Skakel foundered in Central America H...  \n",
       "5471  Ditched aircraft, 3 men in the water. Swam for...  \n",
       "5472  The troopship Britannia was sunk by the German...  \n",
       "5476   Rescuing seaman after ship sunk by German raider  \n",
       "5477  Adrift on raft after their ship was sunk by an...  \n",
       "5520       Japanese freighter Bokuyo Maru burned & sank  \n",
       "5879               Fell overboard from SS Ripley Castle  \n",
       "6042  Jumped overboard from Norwegian steamship Venator  \n",
       "6127                                            Fishing  \n",
       "6233                                     Fell overboard  \n",
       "6399  Swimming after falling overboard from the seal...  \n",
       "6405                                     Fell overboard  \n",
       "6413   a canoe was pursuing a schooner that had forc...  \n",
       "6427                                   Thrown overboard  \n",
       "6451                                           Swimming  \n",
       "6478  British ship Macedon was thrown on her beam en...  \n",
       "6497   Fell or jumped overboard from the liner Rhynland  \n",
       "6520                                            Fishing  \n",
       "6533                      Fell overboard from the Selim  \n",
       "6572  Boat with 5 men capsized while returning to th...  \n",
       "6573  Boat with 5 men capsized while returning to th...  \n",
       "6585                                                NaN  \n",
       "6625                          Swimming to avoid capture  \n",
       "6632                                  Adrift on a raft   \n",
       "6746                                            Fishing  \n",
       "6750                                                NaN  \n",
       "6814                               Hooking into a whale  \n",
       "6826                       Wreck of the schooner Driver  \n",
       "6881  Fell overboard from a frigate & was swallowed ...  \n",
       "6968                                        Free diving  \n",
       "6974                                                NaN  \n",
       "6997                Fishing, wading with string of fish  \n",
       "7009                                                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Filter for sea/ocean and keep both columns\n",
    "sea_ocean_df = df[df['Country_cleaned'].str.contains('sea|ocean', case=False, na=False)][['Country_cleaned', 'Activity']]\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "\n",
    "    display(sea_ocean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16th August 2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Cayo Costa Boca Grande</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Shawn Meuse</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Laceration to right leg below the knee</td>\n",
       "      <td>N</td>\n",
       "      <td>1055 hrs</td>\n",
       "      <td>Lemon shark 1.8 m (6ft)</td>\n",
       "      <td>Johannes Marchand: Kevin McMurray Trackingshar...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Brad Ross</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>None sustained board severly damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>0730hrs</td>\n",
       "      <td>5m (16.5ft) Great White</td>\n",
       "      <td>Bob Myatt GSAF The Guardian: 9 News: ABS News:...</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>Severe injuries no detail</td>\n",
       "      <td>N</td>\n",
       "      <td>1300hrs</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Ralph Collier GSAF and Kevin MCMurray Tracking...</td>\n",
       "      <td>Bahamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Tathra Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bowie Daley</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>None sustained board severely damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>1630hrs</td>\n",
       "      <td>Suspected Great White</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Carolina Beach</td>\n",
       "      <td>Wading</td>\n",
       "      <td>Eleonora Boi</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Bite to thigh area</td>\n",
       "      <td>N</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Kevin McMurray Trackingsharks.com: NY Post</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Year        Type      Country  \\\n",
       "0  16th August 2025  2025.0    Provoked          USA   \n",
       "1       18th August  2025.0  Unprovoked    Australia   \n",
       "2       17th August  2025.0  Unprovoked      Bahamas   \n",
       "3        7th August  2025.0  Unprovoked    Australia   \n",
       "4        1st August  2025.0  Unprovoked  Puerto Rico   \n",
       "\n",
       "                               State                             Location  \\\n",
       "0                            Florida               Cayo Costa Boca Grande   \n",
       "1                                NSW                       Cabarita Beach   \n",
       "2  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "3                                NSW                        Tathra Beach    \n",
       "4                           Carolina                       Carolina Beach   \n",
       "\n",
       "       Activity          Name Sex Age                                  Injury  \\\n",
       "0       Fishing   Shawn Meuse   M   ?  Laceration to right leg below the knee   \n",
       "1       Surfing     Brad Ross   M   ?    None sustained board severly damaged   \n",
       "2  Spearfishing    Not stated   M  63               Severe injuries no detail   \n",
       "3       Surfing   Bowie Daley   M   9   None sustained board severely damaged   \n",
       "4        Wading  Eleonora Boi   F  39                      Bite to thigh area   \n",
       "\n",
       "  Fatal Y/N        Time                 Species   \\\n",
       "0         N    1055 hrs  Lemon shark 1.8 m (6ft)   \n",
       "1         N     0730hrs  5m (16.5ft) Great White   \n",
       "2         N     1300hrs             Undetermined   \n",
       "3         N     1630hrs    Suspected Great White   \n",
       "4         N  Not stated             Undetermined   \n",
       "\n",
       "                                              Source Country_cleaned  \n",
       "0  Johannes Marchand: Kevin McMurray Trackingshar...   United States  \n",
       "1  Bob Myatt GSAF The Guardian: 9 News: ABS News:...       Australia  \n",
       "2  Ralph Collier GSAF and Kevin MCMurray Tracking...         Bahamas  \n",
       "3                                     Bob Myatt GSAF       Australia  \n",
       "4         Kevin McMurray Trackingsharks.com: NY Post     Puerto Rico  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping of common mismatches to ISO pycountry names\n",
    "\n",
    "country_replacements = {\n",
    "    # Abbreviations & short forms\n",
    "    \"Usa\": \"United States\",\n",
    "    \"England\": \"United Kingdom\",\n",
    "    \"Scotland\": \"United Kingdom\",\n",
    "    \"United Arab Emirates (Uae)\": \"United Arab Emirates\",\n",
    "\n",
    "    # Korea\n",
    "    \"Korea\": \"Korea, Republic of\",  \n",
    "    \"South Korea\": \"Korea, Republic of\",\n",
    "\n",
    "    # Variants\n",
    "    \"Burma\": \"Myanmar\",\n",
    "    \"Ceylon\": \"Sri Lanka\",\n",
    "    \"Ceylon (Sri Lanka)\": \"Sri Lanka\",\n",
    "    \"Western Samoa\": \"Samoa\",\n",
    "    \"American Samoa\": \"Samoa\",\n",
    "    \"Zaire\": \"Congo, The Democratic Republic of the\",\n",
    "    \"Columbia\": \"Colombia\",\n",
    "    \"Bahrein\": \"Bahrain\",\n",
    "    \"Maldive Islands\": \"Maldives\",\n",
    "    \"Cape Verde\": \"Cabo Verde\",\n",
    "    \"Palestinian Territories\": \"Palestine, State of\",\n",
    "    \"Taiwan\": \"Taiwan, Province of China\",\n",
    "    \"Macau\": \"Macao\", \n",
    "\n",
    "    # Caribbean & island variations\n",
    "    \"Curacao\": \"Curaçao\",\n",
    "    \"Netherlands Antilles\": \"Curaçao\",\n",
    "    \"Trinidad\": \"Trinidad and Tobago\",\n",
    "    \"Tobago\": \"Trinidad and Tobago\",\n",
    "    \"Trinidad & Tobago\": \"Trinidad and Tobago\",\n",
    "    \"Turks & Caicos\": \"Turks and Caicos Islands\",\n",
    "    \"Turks And Caicos\": \"Turks and Caicos Islands\",\n",
    "\n",
    "    # French territories\n",
    "    \"Reunion\": \"Réunion\",\n",
    "    \"Reunion Island\": \"Réunion\",\n",
    "\n",
    "    # Saint Martin variants\n",
    "    \"St. Martin\": \"Saint Martin (French part)\",\n",
    "    \"St Martin\": \"Saint Martin (French part)\",\n",
    "    \"St. Maartin\": \"Sint Maarten (Dutch part)\",\n",
    "\n",
    "    # Small states/territories\n",
    "    \"Antigua\": \"Antigua and Barbuda\",\n",
    "    \"Nevis\": \"Saint Kitts and Nevis\",\n",
    "    \"St Kitts / Nevis\": \"Saint Kitts and Nevis\",\n",
    "    \"Falkland Islands\": \"Falkland Islands (Malvinas)\",\n",
    "\n",
    "    # Papua New Guinea variants\n",
    "    \"British New Guinea\": \"Papua New Guinea\",\n",
    "    \"New Guinea\": \"Papua New Guinea\",\n",
    "    \"New Britain\": \"Papua New Guinea\",\n",
    "}\n",
    "\n",
    "df[\"Country_cleaned\"] = df[\"Country_cleaned\"].replace(country_replacements)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country_cleaned\n",
      "United States                  2570\n",
      "Australia                      1507\n",
      "South Africa                    599\n",
      "Papua New Guinea                153\n",
      "New Zealand                     146\n",
      "Bahamas                         141\n",
      "Brazil                          122\n",
      "Mexico                          107\n",
      "Italy                            72\n",
      "Fiji                             70\n",
      "New Caledonia                    66\n",
      "Réunion                          65\n",
      "Philippines                      65\n",
      "Egypt                            53\n",
      "Mozambique                       50\n",
      "Cuba                             49\n",
      "Spain                            47\n",
      "United Kingdom                   44\n",
      "India                            41\n",
      "French Polynesia                 39\n",
      "Japan                            36\n",
      "Croatia                          35\n",
      "Jamaica                          32\n",
      "Panama                           32\n",
      "Solomon Islands                  30\n",
      "Indonesia                        25\n",
      "Greece                           24\n",
      "Hong Kong                        24\n",
      "Sri Lanka                        18\n",
      "Costa Rica                       18\n",
      "Tonga                            18\n",
      "Bermuda                          16\n",
      "Vanuatu                          15\n",
      "Samoa                            14\n",
      "Canada                           14\n",
      "France                           13\n",
      "Thailand                         13\n",
      "Marshall Islands                 13\n",
      "Colombia                         12\n",
      "Iraq                             12\n",
      "Ecuador                          11\n",
      "Senegal                          11\n",
      "Seychelles                       10\n",
      "Mauritius                        10\n",
      "Kenya                            10\n",
      "Taiwan, Province of China         9\n",
      "Maldives                          9\n",
      "Sierra Leone                      9\n",
      "Yemen                             9\n",
      "Korea, Republic of                9\n",
      "China                             9\n",
      "Israel                            9\n",
      "Belize                            8\n",
      "Chile                             8\n",
      "Turks and Caicos Islands          8\n",
      "Madagascar                        8\n",
      "Trinidad and Tobago               7\n",
      "Dominican Republic                7\n",
      "Nicaragua                         7\n",
      "Somalia                           6\n",
      "Kiribati                          6\n",
      "Barbados                          6\n",
      "Singapore                         6\n",
      "Honduras                          6\n",
      "Libya                             6\n",
      "Palau                             5\n",
      "Malta                             5\n",
      "Malaysia                          5\n",
      "Saudi Arabia                      5\n",
      "Nigeria                           4\n",
      "Guam                              4\n",
      "Myanmar                           4\n",
      "Portugal                          4\n",
      "Sudan                             4\n",
      "United Arab Emirates              4\n",
      "El Salvador                       4\n",
      "Grenada                           4\n",
      "Uruguay                           4\n",
      "Tunisia                           3\n",
      "Montenegro                        3\n",
      "Guinea                            3\n",
      "Martinique                        3\n",
      "Liberia                           3\n",
      "Lebanon                           3\n",
      "Cabo Verde                        3\n",
      "Guyana                            3\n",
      "Haiti                             3\n",
      "Curaçao                           2\n",
      "Iceland                           2\n",
      "Saint Kitts and Nevis             2\n",
      "Saint Martin (French part)        2\n",
      "Antigua and Barbuda               2\n",
      "Ireland                           2\n",
      "Argentina                         2\n",
      "Namibia                           2\n",
      "Peru                              2\n",
      "Puerto Rico                       2\n",
      "Norway                            2\n",
      "Cayman Islands                    2\n",
      "Falkland Islands (Malvinas)       1\n",
      "Algeria                           1\n",
      "Ghana                             1\n",
      "Greenland                         1\n",
      "Paraguay                          1\n",
      "Cook Islands                      1\n",
      "Georgia                           1\n",
      "Tuvalu                            1\n",
      "Djibouti                          1\n",
      "Sweden                            1\n",
      "Cyprus                            1\n",
      "Sint Maarten (Dutch part)         1\n",
      "Kuwait                            1\n",
      "Monaco                            1\n",
      "Slovenia                          1\n",
      "Northern Mariana Islands          1\n",
      "Guatemala                         1\n",
      "Mayotte                           1\n",
      "Gabon                             1\n",
      "Bangladesh                        1\n",
      "Angola                            1\n",
      "Palestine, State of               1\n",
      "Aruba                             1\n",
      "Comoros                           1\n",
      "Morocco                           1\n",
      "Jordan                            1\n",
      "Bahrain                           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#keeping only entries that match countries in pycountry\n",
    "\n",
    "pycountry_names = {c.name for c in pycountry.countries}\n",
    "df = df[df['Country_cleaned'].isin(pycountry_names)]\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df['Country_cleaned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning format of State column by removing any puntuation, extra spaces, and fixing lower-case and capitalization\n",
    "\n",
    "df['State_cleaned'] = df['State'].astype(str).str.strip().str.lower().str.title().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    \n",
    "    #print(df['State_cleaned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_replacements = {\n",
    "    # USA typos / spacing\n",
    "    \"Floria\": \"Florida\",\n",
    "    \"Noirth Carolina\": \"North Carolina\",\n",
    "    \n",
    "    # Australia typos / spacing\n",
    "    \"Westerm Australia\": \"Western Australia\",\n",
    "    \"Nsw\": \"New South Wales\",\n",
    "    \"New South Ales\": \"New South Wales\",\n",
    "    \"Wa\": \"West Australia\",\n",
    "    \n",
    "    # South Africa typos / spacing\n",
    "    \"KNZ\": \"KwaZulu-Natal\",\n",
    "    \"KZN\": \"KwaZulu-Natal\",\n",
    "    \"Easten Cape Province\": \"Eastern Cape Province\",\n",
    "    \n",
    "    # Mexico typos\n",
    "    \"Quntana Roo\": \"Quintana Roo\",\n",
    "    \"Quinta Roo\": \"Quintana Roo\",\n",
    "    \"Baja \": \"Baja California\",   # kept trailing space as abbreviation\n",
    "    \n",
    "    # Cuba typos\n",
    "    \"Holquin\": \"Holguín\",\n",
    "    \"Holquin Province\": \"Holguín Province\",\n",
    "    \n",
    "    # Caribbean / Bahamas typos\n",
    "    \"New Providence   Isoad\": \"New Providence\",\n",
    "    \"Lucayan Lucayan Archipelago\": \"Lucayan Archipelago\",\n",
    "    \n",
    "    # Philippines / islands\n",
    "    \"Guanacoste\": \"Guanacaste\",\n",
    "    \"Queaon\": \"Quezon\",\n",
    "    \"Batanes Provine\": \"Batanes Province\",\n",
    "    \"Lomaiviti Provine\": \"Lomaiviti Province\",\n",
    "    \n",
    "    # Saint / St. variants\n",
    "    \"5aint-Denis\": \"Saint-Denis\",\n",
    "    \"St. Georges \": \"Saint George’s\",\n",
    "    \n",
    "    # Unknown placeholder\n",
    "    \"?\": \"Unknown\",\n",
    "}\n",
    "df['State_cleaned'] = df['State_cleaned'].replace(state_replacements)\n",
    "\n",
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    \n",
    "    #print(df['State_cleaned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6758, 17)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'Y' 'F' 'M' nan 'n' 'Nq' 'UNKNOWN' 2017 'Y x 2' ' N' 'N ' 'y']\n"
     ]
    }
   ],
   "source": [
    "#Columns Fatal + Deaths\n",
    "#checking all unique values in Fatal, to understand how I can better clean it\n",
    "print(df['Fatal Y/N'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'Y' 'F' 'M' 'NAN' 'NQ' 'UNKNOWN' '' 'YX']\n",
      "1370\n"
     ]
    }
   ],
   "source": [
    "#cleaning Fatal and printing unique values\n",
    "df['Fatal Y/N cleaned'] = df['Fatal Y/N'].astype(str).str.strip().str.upper().apply(lambda x: re.sub(r'[^A-Z]', '', x))\n",
    "print(df['Fatal Y/N cleaned'].unique())\n",
    "\n",
    "#add column \"Death\" and assign a numeric value to Fatal, yes or no\n",
    "deaths_count = {'N': 0, 'Y': 1}\n",
    "df['Death'] = df['Fatal Y/N cleaned'].map(deaths_count)\n",
    "deaths_count = int(df['Death'].sum())\n",
    "print(deaths_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatal Y/N cleaned\n",
      "N          4770\n",
      "Y          1370\n",
      "NAN         538\n",
      "UNKNOWN      69\n",
      "F             5\n",
      "M             3\n",
      "NQ            1\n",
      "              1\n",
      "YX            1\n",
      "Name: count, dtype: int64\n",
      "Death\n",
      "0.0    4770\n",
      "1.0    1370\n",
      "NaN     618\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking all unique values in Fatal after clean-up\n",
    "counts = df['Fatal Y/N cleaned'].value_counts(dropna=False)\n",
    "print(counts)\n",
    "\n",
    "#all data that is neither Y nor N, is replaced with NaN in the transition from numeric values\n",
    "counts = df['Death'].value_counts(dropna=False)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country_cleaned</th>\n",
       "      <th>State_cleaned</th>\n",
       "      <th>Fatal Y/N cleaned</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16th August 2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Cayo Costa Boca Grande</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Shawn Meuse</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Laceration to right leg below the knee</td>\n",
       "      <td>N</td>\n",
       "      <td>1055 hrs</td>\n",
       "      <td>Lemon shark 1.8 m (6ft)</td>\n",
       "      <td>Johannes Marchand: Kevin McMurray Trackingshar...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Florida</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Brad Ross</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>None sustained board severly damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>0730hrs</td>\n",
       "      <td>5m (16.5ft) Great White</td>\n",
       "      <td>Bob Myatt GSAF The Guardian: 9 News: ABS News:...</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>Severe injuries no detail</td>\n",
       "      <td>N</td>\n",
       "      <td>1300hrs</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Ralph Collier GSAF and Kevin MCMurray Tracking...</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean Near Big Grand Cay</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Tathra Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bowie Daley</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>None sustained board severely damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>1630hrs</td>\n",
       "      <td>Suspected Great White</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Carolina Beach</td>\n",
       "      <td>Wading</td>\n",
       "      <td>Eleonora Boi</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Bite to thigh area</td>\n",
       "      <td>N</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Kevin McMurray Trackingsharks.com: NY Post</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Year        Type      Country  \\\n",
       "0  16th August 2025  2025.0    Provoked          USA   \n",
       "1       18th August  2025.0  Unprovoked    Australia   \n",
       "2       17th August  2025.0  Unprovoked      Bahamas   \n",
       "3        7th August  2025.0  Unprovoked    Australia   \n",
       "4        1st August  2025.0  Unprovoked  Puerto Rico   \n",
       "\n",
       "                               State                             Location  \\\n",
       "0                            Florida               Cayo Costa Boca Grande   \n",
       "1                                NSW                       Cabarita Beach   \n",
       "2  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "3                                NSW                        Tathra Beach    \n",
       "4                           Carolina                       Carolina Beach   \n",
       "\n",
       "       Activity          Name Sex Age                                  Injury  \\\n",
       "0       Fishing   Shawn Meuse   M   ?  Laceration to right leg below the knee   \n",
       "1       Surfing     Brad Ross   M   ?    None sustained board severly damaged   \n",
       "2  Spearfishing    Not stated   M  63               Severe injuries no detail   \n",
       "3       Surfing   Bowie Daley   M   9   None sustained board severely damaged   \n",
       "4        Wading  Eleonora Boi   F  39                      Bite to thigh area   \n",
       "\n",
       "  Fatal Y/N        Time                 Species   \\\n",
       "0         N    1055 hrs  Lemon shark 1.8 m (6ft)   \n",
       "1         N     0730hrs  5m (16.5ft) Great White   \n",
       "2         N     1300hrs             Undetermined   \n",
       "3         N     1630hrs    Suspected Great White   \n",
       "4         N  Not stated             Undetermined   \n",
       "\n",
       "                                              Source Country_cleaned  \\\n",
       "0  Johannes Marchand: Kevin McMurray Trackingshar...   United States   \n",
       "1  Bob Myatt GSAF The Guardian: 9 News: ABS News:...       Australia   \n",
       "2  Ralph Collier GSAF and Kevin MCMurray Tracking...         Bahamas   \n",
       "3                                     Bob Myatt GSAF       Australia   \n",
       "4         Kevin McMurray Trackingsharks.com: NY Post     Puerto Rico   \n",
       "\n",
       "                       State_cleaned Fatal Y/N cleaned  Death  \n",
       "0                            Florida                 N    0.0  \n",
       "1                    New South Wales                 N    0.0  \n",
       "2  Atlantic Ocean Near Big Grand Cay                 N    0.0  \n",
       "3                    New South Wales                 N    0.0  \n",
       "4                           Carolina                 N    0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new boolean column called ‘Surfing’ \n",
    "\n",
    "In this column only surfing-related activities are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search terms related to water sports activities\n",
    "search_terms = ['surf', 'surfing', 'bodyboard', 'bodyboarding', 'longboard', 'Longboarding', 'windsurf', 'windsurfing', 'kite', 'paddle']\n",
    "\n",
    "# Create a new boolean column 'Surfing' in the dataframe\n",
    "# This column will be True if any of the search terms are found in the 'Activity' column\n",
    "# The '|'.join() creates a regex pattern that matches any of the search terms\n",
    "# case=False makes the search case-insensitive\n",
    "# na=False treats NaN values as empty strings instead of raising an error\n",
    "df['Surfing'] = df['Activity'].str.contains('|'.join(search_terms), case=False, na=False)\n",
    "\n",
    "# Relocate 'Surfing' column at the fourth position (index 7) \n",
    "cols = list(df.columns)\n",
    "cols.remove('Surfing')\n",
    "cols.insert(7, 'Surfing')\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the 'Year' Column\n",
    "\n",
    "In this section, we'll handle the missing and inconsistent values in the 'Year' column to ensure the data is in the correct format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 6757 entries, 0 to 7041\n",
      "Series name: Year\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "6756 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 105.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the 'Year' column in the dataframe\n",
    "df['Year'].info()"
   ]
  },
  {
   "cell_type": "code",

   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Surfing</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Country_cleaned</th>\n",
       "      <th>Fatal Y/N cleaned</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Reported 08-Jan-2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>False</td>\n",
       "      <td>Kerry Daniel</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>No attack, shark made a threat display</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Liquid Vision 1/8/2017</td>\n",
       "      <td>2017.01.08.R-KerryDaniel.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>6142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  Year     Type    Country       State Location  \\\n",
       "896  Reported 08-Jan-2017   NaN  Invalid  AUSTRALIA  Queensland      NaN   \n",
       "\n",
       "         Activity  Surfing          Name Sex Age  \\\n",
       "896  Spearfishing    False  Kerry Daniel   M  35   \n",
       "\n",
       "                                     Injury Fatal Y/N Time    Species   \\\n",
       "896  No attack, shark made a threat display       NaN  NaN  Bull shark   \n",
       "\n",
       "                     Source                           pdf  \\\n",
       "896  Liquid Vision 1/8/2017  2017.01.08.R-KerryDaniel.pdf   \n",
       "\n",
       "                                          href formula  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                  href   Case Number  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...  2017.01.08.R   \n",
       "\n",
       "    Case Number.1  original order Unnamed: 21 Unnamed: 22 Country_cleaned  \\\n",
       "896  2017.01.08.R          6142.0         NaN         NaN       Australia   \n",
       "\n",
       "    Fatal Y/N cleaned  Death  \n",
       "896               NAN    NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the null values in the Year column\n",
    "df[df['Year'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Surfing</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Country_cleaned</th>\n",
       "      <th>Fatal Y/N cleaned</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Reported 08-Jan-2017</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>False</td>\n",
       "      <td>Kerry Daniel</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>No attack, shark made a threat display</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Liquid Vision 1/8/2017</td>\n",
       "      <td>2017.01.08.R-KerryDaniel.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>6142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date    Year     Type    Country       State Location  \\\n",
       "896  Reported 08-Jan-2017  2017.0  Invalid  AUSTRALIA  Queensland      NaN   \n",
       "\n",
       "         Activity  Surfing          Name Sex Age  \\\n",
       "896  Spearfishing    False  Kerry Daniel   M  35   \n",
       "\n",
       "                                     Injury Fatal Y/N Time    Species   \\\n",
       "896  No attack, shark made a threat display       NaN  NaN  Bull shark   \n",
       "\n",
       "                     Source                           pdf  \\\n",
       "896  Liquid Vision 1/8/2017  2017.01.08.R-KerryDaniel.pdf   \n",
       "\n",
       "                                          href formula  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                  href   Case Number  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...  2017.01.08.R   \n",
       "\n",
       "    Case Number.1  original order Unnamed: 21 Unnamed: 22 Country_cleaned  \\\n",
       "896  2017.01.08.R          6142.0         NaN         NaN       Australia   \n",
       "\n",
       "    Fatal Y/N cleaned  Death  \n",
       "896               NAN    NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the two null entries in the 'Year' column by importing the year from the 'Date' column\n",
    "\n",
    "import re\n",
    "\n",
    "# Extract the year (4 digits) from the 'Date' column for row 896\n",
    "year_896 = re.search(r'\\d{4}', df.loc[896, 'Date']).group()\n",
    "\n",
    "# Update the 'Year' column with the extracted year for row 896\n",
    "df.loc[896, 'Year'] = float(year_896)\n",
    "\n",
    "df.loc[[896]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Year' column to integer data type for numerical operations\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# Print the data type to verify the conversion was successful\n",
    "print(df['Year'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2025, 2024, 2026, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016,\n",
       "       2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005,\n",
       "       2004, 2003, 2002, 2001, 2000, 1999, 1998, 1997, 1996, 1995, 1984,\n",
       "       1994, 1993, 1992, 1991, 1990, 1989, 1969, 1988, 1987, 1986, 1985,\n",
       "       1983, 1982, 1981, 1980, 1979, 1978, 1977, 1976, 1975, 1974, 1973,\n",
       "       1972, 1971, 1970, 1968, 1967, 1966, 1965, 1964, 1963, 1962, 1961,\n",
       "       1960, 1959, 1958, 1957, 1956, 1955, 1954, 1953, 1952, 1951, 1950,\n",
       "       1949, 1948, 1848, 1947, 1946, 1945, 1944, 1943, 1942, 1941, 1940,\n",
       "       1939, 1938, 1937, 1936, 1935, 1934, 1933, 1932, 1931, 1930, 1929,\n",
       "       1928, 1927, 1926, 1925, 1924, 1923, 1922, 1921, 1920, 1919, 1918,\n",
       "       1917, 1916, 1915, 1914, 1913, 1912, 1911, 1910, 1909, 1908, 1907,\n",
       "       1906, 1905, 1904, 1903, 1902, 1901, 1900, 1899, 1898, 1897, 1896,\n",
       "       1895, 1894, 1893, 1892, 1891, 1890, 1889, 1888, 1887, 1886, 1885,\n",
       "       1884, 1883, 1882, 1881, 1880, 1879, 1878, 1877, 1876, 1875, 1874,\n",
       "       1873, 1872, 1871, 1870, 1869, 1868, 1867, 1866, 1865, 1864, 1863,\n",
       "       1862, 1861, 1860, 1859, 1858, 1857, 1856, 1855, 1853, 1852, 1851,\n",
       "       1850, 1849, 1847, 1846, 1845, 1844, 1842, 1841, 1840, 1839, 1837,\n",
       "       1836, 1835, 1834, 1832, 1831, 1830, 1829, 1828, 1827, 1826, 1825,\n",
       "       1823, 1822, 1819, 1818, 1817, 1816, 1810, 1808, 1807, 1805, 1804,\n",
       "       1803, 1802, 1800, 1791, 1788, 1786, 1784, 1783, 1780, 1779, 1776,\n",
       "       1771, 1767, 1764, 1753, 1751, 1749, 1755, 1748, 1738, 1733, 1721,\n",
       "       1703, 1700, 1642, 1691, 1640, 1637, 1617, 1595, 1554, 1543, 1518,\n",
       "       1500, 1000,    5,    0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all unique values from the 'Year' column in the dataframe\n",
    "# Quick overview to check if there is any recent missing year\n",
    "df['Year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the 'Date' Column\n",
    "\n",
    "In this section, we'll handle the missing and inconsistent values in the 'Date' column to ensure the data is in the correct format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1957                    9\n",
       "1958                    7\n",
       "1956                    6\n",
       "1941                    6\n",
       "No date                 6\n",
       "28-Jul-1995             5\n",
       "12-Apr-2001             5\n",
       "2024-07-04 00:00:00     5\n",
       "05-Oct-2003             5\n",
       "1970s                   5\n",
       "Aug-1956                5\n",
       "1955                    5\n",
       "1954                    5\n",
       "1942                    5\n",
       "No date, Before 1963    5\n",
       "15-Apr-2018             4\n",
       "1960                    4\n",
       "1960s                   4\n",
       "1959                    4\n",
       "Before 1906             4\n",
       "27-Dec-2008             4\n",
       "29-Apr-2017             4\n",
       "09-Jan-2010             4\n",
       "14-Jun-2012             4\n",
       "23-Jan-1970             4\n",
       "27-Jul-1952             4\n",
       "1952                    4\n",
       "1950                    4\n",
       "1949                    4\n",
       "1945                    4\n",
       "28-Dec-2014             4\n",
       "04 Jul-2023             4\n",
       "Reported 10-Oct-1906    4\n",
       "09-Jul-1994             4\n",
       "20-Sep-2015             4\n",
       "Before 1958             4\n",
       "02-Sep-2012             3\n",
       "30-Sep-2007             3\n",
       "11-Aug-1997             3\n",
       "2025-02-22 00:00:00     3\n",
       "16-May-1998             3\n",
       "27-Jul-2021             3\n",
       "27-Sep-2002             3\n",
       "09-Dec-1994             3\n",
       "23-Oct-2017             3\n",
       "27-Aug-2014             3\n",
       "14-Sep-2003             3\n",
       "01-Jun-2014             3\n",
       "23-Oct-2018             3\n",
       "31-Oct-2003             3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify and show the top 50 most common dates in the 'Date' column\n",
    "# For quick overview of inconsistent formatting \n",
    "df['Date'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THE MOST COMMON TEXT PATTERNS OF 'DATE' COLUMN ARE:\n",
      " 0\n",
      "Jul         657\n",
      "Aug         591\n",
      "Sep         514\n",
      "Reported    512\n",
      "Jan         494\n",
      "Jun         471\n",
      "Oct         438\n",
      "Apr         435\n",
      "Dec         430\n",
      "Mar         415\n",
      "May         400\n",
      "Nov         396\n",
      "Feb         378\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract date patterns from the 'Date' column using regex\n",
    "# The regex pattern looks for:\n",
    "# - 4-digit years (e.g., 2023)\n",
    "# - Numbers with ordinal suffixes (e.g., 1st, 2nd, 3rd, 4th)\n",
    "# - Date ranges with hyphens (e.g., 1-2, 10-15)\n",
    "# - Year ranges (e.g., 2020-2022)\n",
    "# - Month names or other text (e.g., January, Feb)\n",
    "date_patterns = df['Date'].astype(str).str.extract(r'(\\d{4}|\\d{1,2}(?:st|nd|rd|th)|\\d{1,2}-\\d{1,2}|\\d{4}-\\d{4}|[A-Za-z]+)')\n",
    "\n",
    "# Display the 13 most common date patterns found in the dataset\n",
    "print(f\"\\n THE MOST COMMON TEXT PATTERNS OF 'DATE' COLUMN ARE:\\n\", date_patterns[0].value_counts().head(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118     Reported 02 Nov-2023\n",
      "154     Reported 14 Jul-2023\n",
      "163    Reported 14-June 2023\n",
      "277     Reported 27-Apr-2022\n",
      "298     Reported 10-Feb-2022\n",
      "312     Reported 06-Dec-2021\n",
      "351     Reported 11-Jul-2021\n",
      "505     Reported 14-Mar-2020\n",
      "510     Reported 30-Jan-2020\n",
      "549     Reported 04-Oct-2019\n",
      "577     Reported 17-Jul-2019\n",
      "591     Reported 06-Jun-2019\n",
      "606     Reported 27-Apr-2019\n",
      "656     Reported 16-Oct-2018\n",
      "674     Reported 28-Aug-2018\n",
      "690     Reported 16-Jul-2018\n",
      "697    Reported 09-Jul-2018.\n",
      "719     Reported 30-Apr-2018\n",
      "734     Reported 10-Apr-2018\n",
      "764     Reported 25-Nov-2017\n",
      "Name: Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect entries containing the word 'Reported'\n",
    "# Filter the dataframe to only include rows where the 'Date' column contains the word \"Reported\" \n",
    "df_reported = df[df['Date'].astype(str).str.contains(\"Reported\", case=False)]\n",
    "print(df_reported['Date'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping various month name formats (including abbreviations and different languages) to standardized 3-letter format\n",
    "month_mapping = {\n",
    "    'jan': 'Jan', 'january': 'Jan',\n",
    "    'feb': 'Feb', 'february': 'Feb', 'fev': 'Feb',\n",
    "    'mar': 'Mar', 'march': 'Mar',\n",
    "    'apr': 'Apr', 'april': 'Apr', 'abr': 'Apr',\n",
    "    'may': 'May',\n",
    "    'jun': 'Jun', 'june': 'Jun',\n",
    "    'jul': 'Jul', 'july': 'Jul',\n",
    "    'aug': 'Aug', 'august': 'Aug', 'ago': 'Aug',\n",
    "    'sep': 'Sep', 'september': 'Sep', 'set': 'Sep',\n",
    "    'oct': 'Oct', 'october': 'Oct', 'out': 'Oct',\n",
    "    'nov': 'Nov', 'november': 'Nov',\n",
    "    'dec': 'Dec', 'december': 'Dec', 'dez': 'Dec'\n",
    "}\n",
    "\n",
    "## Create a regex pattern by joining all month keys with '|' (OR operator)\n",
    "all_month_patterns = '|'.join(month_mapping.keys())\n",
    "\n",
    "# Extract month from 'Date' column using regex pattern:\n",
    "# 1. Convert Date column to string\n",
    "# 2. Extract month name using case-insensitive regex (?i)\n",
    "# 3. Convert extracted month to lowercase\n",
    "# 4. Map to standardized format using the month_mapping dictionary\n",
    "df['Month'] = df['Date'].astype(str).str.extract(f'(?i)({all_month_patterns})', expand=False).str.lower().map(month_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect all null entries in the 'Month' column \n",
    "# df[df['Month'].isna()] \n",
    "\n",
    "#Inspect null values in the 'Month' column compared to the values in 'Date' column\n",
    "# print(df[df['Month'].isnull()][['Date', 'Month']].head(20))\n",
    "# print(df[df['Month'].isnull()][['Date', 'Month']].tail(20))\n",
    "df[df['Month'].isnull()][['Date', 'Month']].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date Month\n",
      "19  2025-06-11 00:00:00   NaN\n",
      "21  2025-05-29 00:00:00   NaN\n",
      "22  2025-05-26 00:00:00   NaN\n",
      "23  2025-05-15 00:00:00   NaN\n",
      "24  2025-05-08 00:00:00   NaN\n",
      "25  2025-04-21 00:00:00   NaN\n",
      "26  2025-04-20 00:00:00   NaN\n",
      "27  2025-04-19 00:00:00   NaN\n",
      "28  2025-04-12 00:00:00   NaN\n",
      "29  2025-03-26 00:00:00   NaN\n",
      "30  2025-03-10 00:00:00   NaN\n",
      "31  2025-03-07 00:00:00   NaN\n",
      "32  2025-02-27 00:00:00   NaN\n",
      "34  2025-02-22 00:00:00   NaN\n",
      "35  2025-02-22 00:00:00   NaN\n",
      "36  2025-02-22 00:00:00   NaN\n",
      "37  2025-02-10 00:00:00   NaN\n",
      "38  2025-02-10 00:00:00   NaN\n",
      "40  2025-02-03 00:00:00   NaN\n",
      "41  2025-01-23 00:00:00   NaN\n",
      "Total found: 67\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask to filter rows where 'Date' column matches the format 'YYYY-MM-DD HH:MM:SS'\n",
    "mask = df['Date'].astype(str).str.match(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$')\n",
    "\n",
    "# Filter the dataframe to keep only rows that match the date format pattern\n",
    "# and select only the 'Date' and 'Month' columns\n",
    "df_filtered = df.loc[mask, ['Date', 'Month']]\n",
    "\n",
    "# Display the first 20 rows of the filtered dataframe\n",
    "print(df_filtered.head(20)) \n",
    "\n",
    "# Print the total number of rows that match the date format pattern\n",
    "print(f\"Total found: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping numeric month representations to abbreviated month names\n",
    "numeric_month_mapping = {\n",
    "    '01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr', '05': 'May', '06': 'Jun',\n",
    "    '07': 'Jul', '08': 'Aug', '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'\n",
    "}\n",
    "\n",
    "# Create a boolean mask for rows where 'Month' column contains NaN values\n",
    "nan_mask = df['Month'].isna()\n",
    "\n",
    "# For rows with missing month values, extract the month part (MM) from the 'Date' column\n",
    "# using regex pattern that matches YYYY-MM-DD format\n",
    "extracted_numeric_months = df.loc[nan_mask, 'Date'].astype(str).str.extract(r'\\d{4}-(\\d{2})-\\d{2}', expand=False)\n",
    "\n",
    "# Replace NaN values in 'Month' column with the corresponding month abbreviations\n",
    "df.loc[nan_mask, 'Month'] = extracted_numeric_months.map(numeric_month_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "Jul    763\n",
      "Aug    654\n",
      "Sep    572\n",
      "Jan    552\n",
      "Jun    534\n",
      "Oct    485\n",
      "Apr    485\n",
      "Dec    481\n",
      "Mar    449\n",
      "May    442\n",
      "Nov    433\n",
      "Feb    418\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 6757 entries, 0 to 7041\n",
      "Series name: Month\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "6268 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 363.6+ KB\n",
      "None \n",
      "\n",
      "['Aug' 'Jul' 'Jun' 'May' 'Apr' 'Mar' 'Feb' 'Jan' 'Dec' 'Nov' 'Oct' 'Sep'\n",
      " nan]\n"
     ]
    }
   ],
   "source": [
    "# Reinspect the 'Month' to confirm extraction of values formatted as 'YYYY-MM-DD HH:MM:SS' in the 'Date' column\n",
    "print(df['Month'].value_counts(), '\\n')\n",
    "print(df['Month'].info(), '\\n')\n",
    "print(df['Month'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relocate 'Month' column at the second position (index 1) \n",
    "cols = list(df.columns)\n",
    "cols.remove('Month')\n",
    "cols.insert(1, 'Month')\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aruba', 'Afghanistan', 'Angola', 'Anguilla', 'Åland Islands', 'Albania', 'Andorra', 'United Arab Emirates', 'Argentina', 'Armenia', 'American Samoa', 'Antarctica', 'French Southern Territories', 'Antigua and Barbuda', 'Australia', 'Austria', 'Azerbaijan', 'Burundi', 'Belgium', 'Benin', 'Bonaire, Sint Eustatius and Saba', 'Burkina Faso', 'Bangladesh', 'Bulgaria', 'Bahrain', 'Bahamas', 'Bosnia and Herzegovina', 'Saint Barthélemy', 'Belarus', 'Belize', 'Bermuda', 'Bolivia, Plurinational State of', 'Brazil', 'Barbados', 'Brunei Darussalam', 'Bhutan', 'Bouvet Island', 'Botswana', 'Central African Republic', 'Canada', 'Cocos (Keeling) Islands', 'Switzerland', 'Chile', 'China', \"Côte d'Ivoire\", 'Cameroon', 'Congo, The Democratic Republic of the', 'Congo', 'Cook Islands', 'Colombia', 'Comoros', 'Cabo Verde', 'Costa Rica', 'Cuba', 'Curaçao', 'Christmas Island', 'Cayman Islands', 'Cyprus', 'Czechia', 'Germany', 'Djibouti', 'Dominica', 'Denmark', 'Dominican Republic', 'Algeria', 'Ecuador', 'Egypt', 'Eritrea', 'Western Sahara', 'Spain', 'Estonia', 'Ethiopia', 'Finland', 'Fiji', 'Falkland Islands (Malvinas)', 'France', 'Faroe Islands', 'Micronesia, Federated States of', 'Gabon', 'United Kingdom', 'Georgia', 'Guernsey', 'Ghana', 'Gibraltar', 'Guinea', 'Guadeloupe', 'Gambia', 'Guinea-Bissau', 'Equatorial Guinea', 'Greece', 'Grenada', 'Greenland', 'Guatemala', 'French Guiana', 'Guam', 'Guyana', 'Hong Kong', 'Heard Island and McDonald Islands', 'Honduras', 'Croatia', 'Haiti', 'Hungary', 'Indonesia', 'Isle of Man', 'India', 'British Indian Ocean Territory', 'Ireland', 'Iran, Islamic Republic of', 'Iraq', 'Iceland', 'Israel', 'Italy', 'Jamaica', 'Jersey', 'Jordan', 'Japan', 'Kazakhstan', 'Kenya', 'Kyrgyzstan', 'Cambodia', 'Kiribati', 'Saint Kitts and Nevis', 'Korea, Republic of', 'Kuwait', \"Lao People's Democratic Republic\", 'Lebanon', 'Liberia', 'Libya', 'Saint Lucia', 'Liechtenstein', 'Sri Lanka', 'Lesotho', 'Lithuania', 'Luxembourg', 'Latvia', 'Macao', 'Saint Martin (French part)', 'Morocco', 'Monaco', 'Moldova, Republic of', 'Madagascar', 'Maldives', 'Mexico', 'Marshall Islands', 'North Macedonia', 'Mali', 'Malta', 'Myanmar', 'Montenegro', 'Mongolia', 'Northern Mariana Islands', 'Mozambique', 'Mauritania', 'Montserrat', 'Martinique', 'Mauritius', 'Malawi', 'Malaysia', 'Mayotte', 'Namibia', 'New Caledonia', 'Niger', 'Norfolk Island', 'Nigeria', 'Nicaragua', 'Niue', 'Netherlands', 'Norway', 'Nepal', 'Nauru', 'New Zealand', 'Oman', 'Pakistan', 'Panama', 'Pitcairn', 'Peru', 'Philippines', 'Palau', 'Papua New Guinea', 'Poland', 'Puerto Rico', \"Korea, Democratic People's Republic of\", 'Portugal', 'Paraguay', 'Palestine, State of', 'French Polynesia', 'Qatar', 'Réunion', 'Romania', 'Russian Federation', 'Rwanda', 'Saudi Arabia', 'Sudan', 'Senegal', 'Singapore', 'South Georgia and the South Sandwich Islands', 'Saint Helena, Ascension and Tristan da Cunha', 'Svalbard and Jan Mayen', 'Solomon Islands', 'Sierra Leone', 'El Salvador', 'San Marino', 'Somalia', 'Saint Pierre and Miquelon', 'Serbia', 'South Sudan', 'Sao Tome and Principe', 'Suriname', 'Slovakia', 'Slovenia', 'Sweden', 'Eswatini', 'Sint Maarten (Dutch part)', 'Seychelles', 'Syrian Arab Republic', 'Turks and Caicos Islands', 'Chad', 'Togo', 'Thailand', 'Tajikistan', 'Tokelau', 'Turkmenistan', 'Timor-Leste', 'Tonga', 'Trinidad and Tobago', 'Tunisia', 'Türkiye', 'Tuvalu', 'Taiwan, Province of China', 'Tanzania, United Republic of', 'Uganda', 'Ukraine', 'United States Minor Outlying Islands', 'Uruguay', 'United States', 'Uzbekistan', 'Holy See (Vatican City State)', 'Saint Vincent and the Grenadines', 'Venezuela, Bolivarian Republic of', 'Virgin Islands, British', 'Virgin Islands, U.S.', 'Viet Nam', 'Vanuatu', 'Wallis and Futuna', 'Samoa', 'Yemen', 'South Africa', 'Zambia', 'Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "countries = [c.name for c in pycountry.countries]\n",
    "print(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_states.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
