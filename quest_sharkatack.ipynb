{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/camilla-scandola/project-shark-attack/blob/main/quest_sharkatack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEzYg3TCIR4L",
    "outputId": "403583b3-1382-4d2b-ba8b-46ec8f49d2ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\tozes\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\tozes\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tozes\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tozes\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tozes\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tozes\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YncNJ57OIbev",
    "outputId": "2d247253-d2c9-44c9-e750-ec09bd3d3c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\tozes\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\tozes\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJx1JH0XIkrR",
    "outputId": "507f77eb-e5c9-4f42-cd12-bbbb03dd7429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\users\\tozes\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry in c:\\users\\tozes\\anaconda3\\lib\\site-packages (24.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AdlQ0fITIp6Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PGVDRxp072hj"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('GSAF5.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "dM138EG4K6ze",
    "outputId": "d15da878-a006-454a-a7d9-e4d4fb9a2aa5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16th August 2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Cayo Costa Boca Grande</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Shawn Meuse</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Laceration to right leg below the knee</td>\n",
       "      <td>N</td>\n",
       "      <td>1055 hrs</td>\n",
       "      <td>Lemon shark 1.8 m (6ft)</td>\n",
       "      <td>Johannes Marchand: Kevin McMurray Trackingshar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Brad Ross</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>None sustained board severly damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>0730hrs</td>\n",
       "      <td>5m (16.5ft) Great White</td>\n",
       "      <td>Bob Myatt GSAF The Guardian: 9 News: ABS News:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>Severe injuries no detail</td>\n",
       "      <td>N</td>\n",
       "      <td>1300hrs</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Ralph Collier GSAF and Kevin MCMurray Tracking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Tathra Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bowie Daley</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>None sustained board severely damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>1630hrs</td>\n",
       "      <td>Suspected Great White</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Carolina Beach</td>\n",
       "      <td>Wading</td>\n",
       "      <td>Eleonora Boi</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Bite to thigh area</td>\n",
       "      <td>N</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Kevin McMurray Trackingsharks.com: NY Post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Year        Type      Country  \\\n",
       "0  16th August 2025  2025.0    Provoked          USA   \n",
       "1       18th August  2025.0  Unprovoked    Australia   \n",
       "2       17th August  2025.0  Unprovoked      Bahamas   \n",
       "3        7th August  2025.0  Unprovoked    Australia   \n",
       "4        1st August  2025.0  Unprovoked  Puerto Rico   \n",
       "\n",
       "                               State                             Location  \\\n",
       "0                            Florida               Cayo Costa Boca Grande   \n",
       "1                                NSW                       Cabarita Beach   \n",
       "2  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "3                                NSW                        Tathra Beach    \n",
       "4                           Carolina                       Carolina Beach   \n",
       "\n",
       "       Activity          Name Sex Age                                  Injury  \\\n",
       "0       Fishing   Shawn Meuse   M   ?  Laceration to right leg below the knee   \n",
       "1       Surfing     Brad Ross   M   ?    None sustained board severly damaged   \n",
       "2  Spearfishing    Not stated   M  63               Severe injuries no detail   \n",
       "3       Surfing   Bowie Daley   M   9   None sustained board severely damaged   \n",
       "4        Wading  Eleonora Boi   F  39                      Bite to thigh area   \n",
       "\n",
       "  Fatal Y/N        Time                 Species   \\\n",
       "0         N    1055 hrs  Lemon shark 1.8 m (6ft)   \n",
       "1         N     0730hrs  5m (16.5ft) Great White   \n",
       "2         N     1300hrs             Undetermined   \n",
       "3         N     1630hrs    Suspected Great White   \n",
       "4         N  Not stated             Undetermined   \n",
       "\n",
       "                                              Source  pdf href formula href  \\\n",
       "0  Johannes Marchand: Kevin McMurray Trackingshar...  NaN          NaN  NaN   \n",
       "1  Bob Myatt GSAF The Guardian: 9 News: ABS News:...  NaN          NaN  NaN   \n",
       "2  Ralph Collier GSAF and Kevin MCMurray Tracking...  NaN          NaN  NaN   \n",
       "3                                     Bob Myatt GSAF  NaN          NaN  NaN   \n",
       "4         Kevin McMurray Trackingsharks.com: NY Post  NaN          NaN  NaN   \n",
       "\n",
       "  Case Number Case Number.1  original order Unnamed: 21 Unnamed: 22  \n",
       "0         NaN           NaN             NaN         NaN         NaN  \n",
       "1         NaN           NaN             NaN         NaN         NaN  \n",
       "2         NaN           NaN             NaN         NaN         NaN  \n",
       "3         NaN           NaN             NaN         NaN         NaN  \n",
       "4         NaN           NaN             NaN         NaN         NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TAMzlrC176A2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "485\n",
      "567\n",
      "7037             AUSTRALIA\n",
      "7038             AUSTRALIA\n",
      "7039                   USA\n",
      "7040                PANAMA\n",
      "7041    CEYLON (SRI LANKA)\n",
      "Name: Country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#overview of the dataset\n",
    "\n",
    "missing_country = int(df['Country'].isna().sum())\n",
    "print(missing_country)\n",
    "\n",
    "missing_state = int(df['State'].isna().sum())\n",
    "print(missing_state)\n",
    "\n",
    "missing_location = int(df['Location'].isna().sum())\n",
    "print(missing_location)\n",
    "\n",
    "print(df['Country'].tail())\n",
    "\n",
    "#suggestion: drop all the null values under country (because they won't make a big difference in the analysis, being 50 out of 7041)\n",
    "#df['Country'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    Cayo Costa Boca Grande\n",
       "1                            Cabarita Beach\n",
       "2       North of Grand Bahama near Freeport\n",
       "3                             Tathra Beach \n",
       "4                            Carolina Beach\n",
       "                       ...                 \n",
       "7037                            Roebuck Bay\n",
       "7038                              undefined\n",
       "7039                         Ocracoke Inlet\n",
       "7040                   Panama Bay 8ºN, 79ºW\n",
       "7041    Below the English fort, Trincomalee\n",
       "Name: Location, Length: 7042, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suggestion: the number of missing values in states and locations is a lot more significant, so I'd replace them with undefined for the time being\n",
    "df['State'].fillna('undefined')\n",
    "df['Location'].fillna('undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country_cleaned\n",
      "Usa                                      2570\n",
      "Australia                                1507\n",
      "South Africa                              599\n",
      "New Zealand                               146\n",
      "Bahamas                                   141\n",
      "Papua New Guinea                          136\n",
      "Brazil                                    122\n",
      "Mexico                                    107\n",
      "Italy                                      72\n",
      "Fiji                                       70\n",
      "New Caledonia                              66\n",
      "Philippines                                65\n",
      "Reunion                                    60\n",
      "Egypt                                      53\n",
      "Mozambique                                 50\n",
      "Nan                                        50\n",
      "Cuba                                       49\n",
      "Spain                                      47\n",
      "India                                      41\n",
      "French Polynesia                           39\n",
      "Japan                                      36\n",
      "Croatia                                    35\n",
      "Jamaica                                    32\n",
      "Panama                                     32\n",
      "Solomon Islands                            30\n",
      "Iran                                       29\n",
      "Indonesia                                  25\n",
      "England                                    25\n",
      "Greece                                     24\n",
      "Hong Kong                                  24\n",
      "Pacific Ocean                              19\n",
      "Tonga                                      18\n",
      "Costa Rica                                 18\n",
      "Atlantic Ocean                             17\n",
      "Bermuda                                    16\n",
      "Vietnam                                    15\n",
      "Vanuatu                                    15\n",
      "Canada                                     14\n",
      "Sri Lanka                                  14\n",
      "Marshall Islands                           13\n",
      "France                                     13\n",
      "Thailand                                   13\n",
      "South Atlantic Ocean                       12\n",
      "Iraq                                       12\n",
      "Turkey                                     12\n",
      "Venezuela                                  11\n",
      "Ecuador                                    11\n",
      "United Kingdom                             11\n",
      "Senegal                                    11\n",
      "Seychelles                                 10\n",
      "Samoa                                      10\n",
      "Kenya                                      10\n",
      "Columbia                                   10\n",
      "New Guinea                                 10\n",
      "Mauritius                                  10\n",
      "Yemen                                       9\n",
      "Sierra Leone                                9\n",
      "Taiwan                                      9\n",
      "Israel                                      9\n",
      "China                                       9\n",
      "Belize                                      8\n",
      "Chile                                       8\n",
      "Scotland                                    8\n",
      "Madagascar                                  8\n",
      "South Korea                                 8\n",
      "Caribbean Sea                               8\n",
      "Tanzania                                    8\n",
      "Nicaragua                                   7\n",
      "North Pacific Ocean                         7\n",
      "Dominican Republic                          7\n",
      "Indian Ocean                                7\n",
      "Okinawa                                     6\n",
      "Kiribati                                    6\n",
      "Singapore                                   6\n",
      "New Britain                                 6\n",
      "Barbados                                    6\n",
      "Somalia                                     6\n",
      "Maldives                                    6\n",
      "Libya                                       6\n",
      "Honduras                                    6\n",
      "Palau                                       5\n",
      "Malaysia                                    5\n",
      "Reunion Island                              5\n",
      "Malta                                       5\n",
      "Saudi Arabia                                5\n",
      "Turks & Caicos                              5\n",
      "Mid Atlantic Ocean                          5\n",
      "Azores                                      5\n",
      "North Atlantic Ocean                        5\n",
      "Grenada                                     4\n",
      "Sudan                                       4\n",
      "El Salvador                                 4\n",
      "Russia                                      4\n",
      "Burma                                       4\n",
      "Nigeria                                     4\n",
      "Persian Gulf                                4\n",
      "Portugal                                    4\n",
      "Guam                                        4\n",
      "Uruguay                                     4\n",
      "Haiti                                       3\n",
      "American Samoa                              3\n",
      "Martinique                                  3\n",
      "Lebanon                                     3\n",
      "Ceylon                                      3\n",
      "Guinea                                      3\n",
      "Liberia                                     3\n",
      "Tunisia                                     3\n",
      "Tobago                                      3\n",
      "Trinidad & Tobago                           3\n",
      "Turks And Caicos                            3\n",
      "Maldive Islands                             3\n",
      "Cape Verde                                  3\n",
      "Guyana                                      3\n",
      "Micronesia                                  3\n",
      "Montenegro                                  3\n",
      "Cayman Islands                              2\n",
      "Puerto Rico                                 2\n",
      "Peru                                        2\n",
      "Colombia                                    2\n",
      "Ireland                                     2\n",
      "Antigua                                     2\n",
      "Iceland                                     2\n",
      "Crete                                       2\n",
      "Central Pacific                             2\n",
      "Southwest Pacific Ocean                     2\n",
      "Java                                        2\n",
      "United Arab Emirates (Uae)                  2\n",
      "Johnston Island                             2\n",
      "South Pacific Ocean                         2\n",
      "Namibia                                     2\n",
      "Norway                                      2\n",
      "St Helena, British Overseas Territory       2\n",
      "United Arab Emirates                        2\n",
      "Argentina                                   2\n",
      "West Indies                                 2\n",
      "Mediterranean Sea                           2\n",
      "St. Martin                                  1\n",
      "Comoros                                     1\n",
      "St Martin                                   1\n",
      "Palestinian Territories                     1\n",
      "Aruba                                       1\n",
      "British Overseas Territory                  1\n",
      "Coral Sea                                   1\n",
      "Morocco                                     1\n",
      "Trinidad                                    1\n",
      "Canary Islands                              1\n",
      "Hawaii                                      1\n",
      "Jordan                                      1\n",
      "St Kitts / Nevis                            1\n",
      "Diego Garcia                                1\n",
      "Red Sea / Indian Ocean                      1\n",
      "North Sea                                   1\n",
      "British West Indies                         1\n",
      "Federated States Of Micronesia              1\n",
      "Red Sea                                     1\n",
      "Western Samoa                               1\n",
      "British Isles                               1\n",
      "South China Sea                             1\n",
      "Bangladesh                                  1\n",
      "Angola                                      1\n",
      "British Virgin Islands                      1\n",
      "St. Maartin                                 1\n",
      "Grand Cayman                                1\n",
      "Northern Arabian Sea                        1\n",
      "Egypt / Israel                              1\n",
      "Nevis                                       1\n",
      "Gulf Of Aden                                1\n",
      "Admiralty Islands                           1\n",
      "Solomon Islands / Vanuatu                   1\n",
      "Guatemala                                   1\n",
      "Mayotte                                     1\n",
      "Slovenia                                    1\n",
      "Bay Of Bengal                               1\n",
      "Italy / Croatia                             1\n",
      "Iran / Iraq                                 1\n",
      "Netherlands Antilles                        1\n",
      "Northern Mariana Islands                    1\n",
      "Sudan?                                      1\n",
      "The Balkans                                 1\n",
      "Gabon                                       1\n",
      "Andaman / Nicobar Islandas                  1\n",
      "Cyprus                                      1\n",
      "Falkland Islands                            1\n",
      "Kuwait                                      1\n",
      "San Domingo                                 1\n",
      "Monaco                                      1\n",
      "Mid-Pacifc Ocean                            1\n",
      "Curacao                                     1\n",
      "Paraguay                                    1\n",
      "Georgia                                     1\n",
      "Ocean                                       1\n",
      "Tuvalu                                      1\n",
      "Syria                                       1\n",
      "Indian Ocean?                               1\n",
      "Andaman Islands                             1\n",
      "Equatorial Guinea / Cameroon                1\n",
      "British New Guinea                          1\n",
      "Cook Islands                                1\n",
      "Africa                                      1\n",
      "Coast Of Africa                             1\n",
      "Algeria                                     1\n",
      "Tasman Sea                                  1\n",
      "Ghana                                       1\n",
      "Greenland                                   1\n",
      "Sweden                                      1\n",
      "Roatan                                      1\n",
      "Between Portugal & India                    1\n",
      "Djibouti                                    1\n",
      "Bahrein                                     1\n",
      "Korea                                       1\n",
      "Red Sea?                                    1\n",
      "Asia?                                       1\n",
      "Ceylon (Sri Lanka)                          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#if needed, imported pycountry to check all standard country names + \n",
    "\n",
    "import pycountry\n",
    "\n",
    "df['Country_cleaned'] = df['Country'].astype(str).str.strip().str.lower().str.title()\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    \n",
    "    print(df['Country_cleaned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Country_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16th August 2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Cayo Costa Boca Grande</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Shawn Meuse</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Laceration to right leg below the knee</td>\n",
       "      <td>N</td>\n",
       "      <td>1055 hrs</td>\n",
       "      <td>Lemon shark 1.8 m (6ft)</td>\n",
       "      <td>Johannes Marchand: Kevin McMurray Trackingshar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Brad Ross</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>None sustained board severly damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>0730hrs</td>\n",
       "      <td>5m (16.5ft) Great White</td>\n",
       "      <td>Bob Myatt GSAF The Guardian: 9 News: ABS News:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>Severe injuries no detail</td>\n",
       "      <td>N</td>\n",
       "      <td>1300hrs</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Ralph Collier GSAF and Kevin MCMurray Tracking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bahamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Tathra Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bowie Daley</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>None sustained board severely damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>1630hrs</td>\n",
       "      <td>Suspected Great White</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Carolina Beach</td>\n",
       "      <td>Wading</td>\n",
       "      <td>Eleonora Boi</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Bite to thigh area</td>\n",
       "      <td>N</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Kevin McMurray Trackingsharks.com: NY Post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Year        Type      Country  \\\n",
       "0  16th August 2025  2025.0    Provoked          USA   \n",
       "1       18th August  2025.0  Unprovoked    Australia   \n",
       "2       17th August  2025.0  Unprovoked      Bahamas   \n",
       "3        7th August  2025.0  Unprovoked    Australia   \n",
       "4        1st August  2025.0  Unprovoked  Puerto Rico   \n",
       "\n",
       "                               State                             Location  \\\n",
       "0                            Florida               Cayo Costa Boca Grande   \n",
       "1                                NSW                       Cabarita Beach   \n",
       "2  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "3                                NSW                        Tathra Beach    \n",
       "4                           Carolina                       Carolina Beach   \n",
       "\n",
       "       Activity          Name Sex Age                                  Injury  \\\n",
       "0       Fishing   Shawn Meuse   M   ?  Laceration to right leg below the knee   \n",
       "1       Surfing     Brad Ross   M   ?    None sustained board severly damaged   \n",
       "2  Spearfishing    Not stated   M  63               Severe injuries no detail   \n",
       "3       Surfing   Bowie Daley   M   9   None sustained board severely damaged   \n",
       "4        Wading  Eleonora Boi   F  39                      Bite to thigh area   \n",
       "\n",
       "  Fatal Y/N        Time                 Species   \\\n",
       "0         N    1055 hrs  Lemon shark 1.8 m (6ft)   \n",
       "1         N     0730hrs  5m (16.5ft) Great White   \n",
       "2         N     1300hrs             Undetermined   \n",
       "3         N     1630hrs    Suspected Great White   \n",
       "4         N  Not stated             Undetermined   \n",
       "\n",
       "                                              Source  pdf href formula href  \\\n",
       "0  Johannes Marchand: Kevin McMurray Trackingshar...  NaN          NaN  NaN   \n",
       "1  Bob Myatt GSAF The Guardian: 9 News: ABS News:...  NaN          NaN  NaN   \n",
       "2  Ralph Collier GSAF and Kevin MCMurray Tracking...  NaN          NaN  NaN   \n",
       "3                                     Bob Myatt GSAF  NaN          NaN  NaN   \n",
       "4         Kevin McMurray Trackingsharks.com: NY Post  NaN          NaN  NaN   \n",
       "\n",
       "  Case Number Case Number.1  original order Unnamed: 21 Unnamed: 22  \\\n",
       "0         NaN           NaN             NaN         NaN         NaN   \n",
       "1         NaN           NaN             NaN         NaN         NaN   \n",
       "2         NaN           NaN             NaN         NaN         NaN   \n",
       "3         NaN           NaN             NaN         NaN         NaN   \n",
       "4         NaN           NaN             NaN         NaN         NaN   \n",
       "\n",
       "  Country_cleaned  \n",
       "0   United States  \n",
       "1       Australia  \n",
       "2         Bahamas  \n",
       "3       Australia  \n",
       "4     Puerto Rico  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping of common mismatches to ISO pycountry names\n",
    "replacements = {\n",
    "    # Abbreviations & Short forms\n",
    "    \"Usa\": \"United States\",\n",
    "    \"UK\": \"United Kingdom\",\n",
    "    \"UAE\": \"United Arab Emirates\",\n",
    "\n",
    "    # Alternative spellings\n",
    "    \"South Korea\": \"Korea, Republic of\",\n",
    "    \"North Korea\": \"Korea, Democratic People's Republic of\",\n",
    "    \"Russia\": \"Russian Federation\",\n",
    "    \"Iran\": \"Iran, Islamic Republic of\",\n",
    "    \"Syria\": \"Syrian Arab Republic\",\n",
    "    \"Tanzania\": \"Tanzania, United Republic of\",\n",
    "    \"Vietnam\": \"Viet Nam\",\n",
    "    \"Turkey\": \"Türkiye\",\n",
    "    \"Bolivia\": \"Bolivia, Plurinational State of\",\n",
    "    \"Venezuela\": \"Venezuela, Bolivarian Republic of\",\n",
    "    \"Moldova\": \"Moldova, Republic of\",\n",
    "    \"Laos\": \"Lao People's Democratic Republic\",\n",
    "    \"Palestinian Territories\": \"Palestine, State of\",\n",
    "    \"Micronesia\": \"Micronesia, Federated States of\",\n",
    "    \"Macedonia\": \"North Macedonia\",\n",
    "\n",
    "    # Historical names\n",
    "    \"Burma\": \"Myanmar\",\n",
    "    \"Ceylon\": \"Sri Lanka\",\n",
    "    \"Ceylon (Sri Lanka)\": \"Sri Lanka\",\n",
    "    \"Western Samoa\": \"Samoa\",\n",
    "    \"Zaire\": \"Congo, The Democratic Republic of the\",\n",
    "\n",
    "    # Variations / territories that map to countries\n",
    "    \"Curacao\": \"Curaçao\",\n",
    "    \"St. Martin\": \"Saint Martin (French part)\",\n",
    "    \"St Martin\": \"Saint Martin (French part)\",\n",
    "    \"St. Maartin\": \"Sint Maarten (Dutch part)\",\n",
    "    \"Reunion\": \"Réunion\",\n",
    "    \"Reunion Island\": \"Réunion\",\n",
    "    \"Bahrein\": \"Bahrain\",\n",
    "    \"Cape Verde\": \"Cabo Verde\",\n",
    "    \"Taiwan\": \"Taiwan, Province of China\",\n",
    "    \"Maldive Islands\": \"Maldives\",\n",
    "}\n",
    "\n",
    "df[\"Country_cleaned\"] = df[\"Country_cleaned\"].replace(replacements)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country_cleaned\n",
      "United States                        2570\n",
      "Australia                            1507\n",
      "South Africa                          599\n",
      "New Zealand                           146\n",
      "Bahamas                               141\n",
      "Papua New Guinea                      136\n",
      "Brazil                                122\n",
      "Mexico                                107\n",
      "Italy                                  72\n",
      "Fiji                                   70\n",
      "New Caledonia                          66\n",
      "Réunion                                65\n",
      "Philippines                            65\n",
      "Egypt                                  53\n",
      "Mozambique                             50\n",
      "Cuba                                   49\n",
      "Spain                                  47\n",
      "India                                  41\n",
      "French Polynesia                       39\n",
      "Japan                                  36\n",
      "Croatia                                35\n",
      "Jamaica                                32\n",
      "Panama                                 32\n",
      "Solomon Islands                        30\n",
      "Iran, Islamic Republic of              29\n",
      "Indonesia                              25\n",
      "Greece                                 24\n",
      "Hong Kong                              24\n",
      "Tonga                                  18\n",
      "Costa Rica                             18\n",
      "Sri Lanka                              18\n",
      "Bermuda                                16\n",
      "Viet Nam                               15\n",
      "Vanuatu                                15\n",
      "Canada                                 14\n",
      "Marshall Islands                       13\n",
      "France                                 13\n",
      "Thailand                               13\n",
      "Iraq                                   12\n",
      "Türkiye                                12\n",
      "Senegal                                11\n",
      "Venezuela, Bolivarian Republic of      11\n",
      "United Kingdom                         11\n",
      "Ecuador                                11\n",
      "Samoa                                  11\n",
      "Mauritius                              10\n",
      "Kenya                                  10\n",
      "Seychelles                             10\n",
      "Taiwan, Province of China               9\n",
      "Israel                                  9\n",
      "Yemen                                   9\n",
      "China                                   9\n",
      "Maldives                                9\n",
      "Sierra Leone                            9\n",
      "Korea, Republic of                      8\n",
      "Madagascar                              8\n",
      "Tanzania, United Republic of            8\n",
      "Belize                                  8\n",
      "Chile                                   8\n",
      "Dominican Republic                      7\n",
      "Nicaragua                               7\n",
      "Kiribati                                6\n",
      "Honduras                                6\n",
      "Barbados                                6\n",
      "Somalia                                 6\n",
      "Libya                                   6\n",
      "Singapore                               6\n",
      "Palau                                   5\n",
      "Malaysia                                5\n",
      "Saudi Arabia                            5\n",
      "Malta                                   5\n",
      "Portugal                                4\n",
      "Uruguay                                 4\n",
      "Grenada                                 4\n",
      "Myanmar                                 4\n",
      "Sudan                                   4\n",
      "El Salvador                             4\n",
      "Russian Federation                      4\n",
      "Nigeria                                 4\n",
      "Guam                                    4\n",
      "Cabo Verde                              3\n",
      "Guyana                                  3\n",
      "Lebanon                                 3\n",
      "Guinea                                  3\n",
      "Martinique                              3\n",
      "American Samoa                          3\n",
      "Haiti                                   3\n",
      "Montenegro                              3\n",
      "Liberia                                 3\n",
      "Micronesia, Federated States of         3\n",
      "Tunisia                                 3\n",
      "Colombia                                2\n",
      "Argentina                               2\n",
      "Saint Martin (French part)              2\n",
      "Puerto Rico                             2\n",
      "United Arab Emirates                    2\n",
      "Cayman Islands                          2\n",
      "Ireland                                 2\n",
      "Iceland                                 2\n",
      "Norway                                  2\n",
      "Peru                                    2\n",
      "Namibia                                 2\n",
      "Morocco                                 1\n",
      "Palestine, State of                     1\n",
      "Jordan                                  1\n",
      "Comoros                                 1\n",
      "Aruba                                   1\n",
      "Bangladesh                              1\n",
      "Sint Maarten (Dutch part)               1\n",
      "Angola                                  1\n",
      "Northern Mariana Islands                1\n",
      "Guatemala                               1\n",
      "Mayotte                                 1\n",
      "Gabon                                   1\n",
      "Kuwait                                  1\n",
      "Monaco                                  1\n",
      "Curaçao                                 1\n",
      "Slovenia                                1\n",
      "Paraguay                                1\n",
      "Georgia                                 1\n",
      "Syrian Arab Republic                    1\n",
      "Cyprus                                  1\n",
      "Tuvalu                                  1\n",
      "Cook Islands                            1\n",
      "Algeria                                 1\n",
      "Ghana                                   1\n",
      "Greenland                               1\n",
      "Sweden                                  1\n",
      "Djibouti                                1\n",
      "Bahrain                                 1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pycountry_names = {c.name for c in pycountry.countries}\n",
    "df = df[df['Country_cleaned'].isin(pycountry_names)]\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df['Country_cleaned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'Y' 'F' 'M' nan 'n' 'Nq' 'UNKNOWN' 2017 'Y x 2' ' N' 'N ']\n"
     ]
    }
   ],
   "source": [
    "#Columns Fatal + Deaths\n",
    "#checking all unique values in Fatal, to understand how I can better clean it\n",
    "print(df['Fatal Y/N'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N' 'Y' 'F' 'M' 'NAN' 'NQ' 'UNKNOWN' '' 'YX']\n",
      "1376\n"
     ]
    }
   ],
   "source": [
    "#cleaning Fatal and printing unique values\n",
    "df['Fatal Y/N cleaned'] = df['Fatal Y/N'].astype(str).str.strip().str.upper().apply(lambda x: re.sub(r'[^A-Z]', '', x))\n",
    "print(df['Fatal Y/N cleaned'].unique())\n",
    "\n",
    "#add column \"Death\" and assign a numeric value to Fatal, yes or no\n",
    "deaths_count = {'N': 0, 'Y': 1}\n",
    "df['Death'] = df['Fatal Y/N cleaned'].map(deaths_count)\n",
    "deaths_count = int(df['Death'].sum())\n",
    "print(deaths_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatal Y/N cleaned\n",
      "N          4766\n",
      "Y          1376\n",
      "NAN         535\n",
      "UNKNOWN      69\n",
      "F             5\n",
      "M             3\n",
      "NQ            1\n",
      "              1\n",
      "YX            1\n",
      "Name: count, dtype: int64\n",
      "Death\n",
      "0.0    4766\n",
      "1.0    1376\n",
      "NaN     615\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking all unique values in Fatal after clean-up\n",
    "counts = df['Fatal Y/N cleaned'].value_counts(dropna=False)\n",
    "print(counts)\n",
    "\n",
    "#all data that is neither Y nor N, is replaced with NaN in the transition from numeric values\n",
    "counts = df['Death'].value_counts(dropna=False)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Country_cleaned</th>\n",
       "      <th>Fatal Y/N cleaned</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16th August 2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Cayo Costa Boca Grande</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Shawn Meuse</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>Laceration to right leg below the knee</td>\n",
       "      <td>N</td>\n",
       "      <td>1055 hrs</td>\n",
       "      <td>Lemon shark 1.8 m (6ft)</td>\n",
       "      <td>Johannes Marchand: Kevin McMurray Trackingshar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Brad Ross</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>None sustained board severly damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>0730hrs</td>\n",
       "      <td>5m (16.5ft) Great White</td>\n",
       "      <td>Bob Myatt GSAF The Guardian: 9 News: ABS News:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>Severe injuries no detail</td>\n",
       "      <td>N</td>\n",
       "      <td>1300hrs</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Ralph Collier GSAF and Kevin MCMurray Tracking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Tathra Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bowie Daley</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>None sustained board severely damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>1630hrs</td>\n",
       "      <td>Suspected Great White</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Carolina Beach</td>\n",
       "      <td>Wading</td>\n",
       "      <td>Eleonora Boi</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>Bite to thigh area</td>\n",
       "      <td>N</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Kevin McMurray Trackingsharks.com: NY Post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Year        Type      Country  \\\n",
       "0  16th August 2025  2025.0    Provoked          USA   \n",
       "1       18th August  2025.0  Unprovoked    Australia   \n",
       "2       17th August  2025.0  Unprovoked      Bahamas   \n",
       "3        7th August  2025.0  Unprovoked    Australia   \n",
       "4        1st August  2025.0  Unprovoked  Puerto Rico   \n",
       "\n",
       "                               State                             Location  \\\n",
       "0                            Florida               Cayo Costa Boca Grande   \n",
       "1                                NSW                       Cabarita Beach   \n",
       "2  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "3                                NSW                        Tathra Beach    \n",
       "4                           Carolina                       Carolina Beach   \n",
       "\n",
       "       Activity          Name Sex Age                                  Injury  \\\n",
       "0       Fishing   Shawn Meuse   M   ?  Laceration to right leg below the knee   \n",
       "1       Surfing     Brad Ross   M   ?    None sustained board severly damaged   \n",
       "2  Spearfishing    Not stated   M  63               Severe injuries no detail   \n",
       "3       Surfing   Bowie Daley   M   9   None sustained board severely damaged   \n",
       "4        Wading  Eleonora Boi   F  39                      Bite to thigh area   \n",
       "\n",
       "  Fatal Y/N        Time                 Species   \\\n",
       "0         N    1055 hrs  Lemon shark 1.8 m (6ft)   \n",
       "1         N     0730hrs  5m (16.5ft) Great White   \n",
       "2         N     1300hrs             Undetermined   \n",
       "3         N     1630hrs    Suspected Great White   \n",
       "4         N  Not stated             Undetermined   \n",
       "\n",
       "                                              Source  pdf href formula href  \\\n",
       "0  Johannes Marchand: Kevin McMurray Trackingshar...  NaN          NaN  NaN   \n",
       "1  Bob Myatt GSAF The Guardian: 9 News: ABS News:...  NaN          NaN  NaN   \n",
       "2  Ralph Collier GSAF and Kevin MCMurray Tracking...  NaN          NaN  NaN   \n",
       "3                                     Bob Myatt GSAF  NaN          NaN  NaN   \n",
       "4         Kevin McMurray Trackingsharks.com: NY Post  NaN          NaN  NaN   \n",
       "\n",
       "  Case Number Case Number.1  original order Unnamed: 21 Unnamed: 22  \\\n",
       "0         NaN           NaN             NaN         NaN         NaN   \n",
       "1         NaN           NaN             NaN         NaN         NaN   \n",
       "2         NaN           NaN             NaN         NaN         NaN   \n",
       "3         NaN           NaN             NaN         NaN         NaN   \n",
       "4         NaN           NaN             NaN         NaN         NaN   \n",
       "\n",
       "  Country_cleaned Fatal Y/N cleaned  Death  \n",
       "0   United States                 N    0.0  \n",
       "1       Australia                 N    0.0  \n",
       "2         Bahamas                 N    0.0  \n",
       "3       Australia                 N    0.0  \n",
       "4     Puerto Rico                 N    0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new boolean column called ‘Surfing’ \n",
    "\n",
    "In this column only surfing-related activities are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search terms related to water sports activities\n",
    "search_terms = ['surf', 'surfing', 'bodyboard', 'bodyboarding', 'longboard', 'Longboarding', 'windsurf', 'windsurfing', 'kite', 'paddle']\n",
    "\n",
    "# Create a new boolean column 'Surfing' in the dataframe\n",
    "# This column will be True if any of the search terms are found in the 'Activity' column\n",
    "# The '|'.join() creates a regex pattern that matches any of the search terms\n",
    "# case=False makes the search case-insensitive\n",
    "# na=False treats NaN values as empty strings instead of raising an error\n",
    "df['Surfing'] = df['Activity'].str.contains('|'.join(search_terms), case=False, na=False)\n",
    "\n",
    "# Relocate 'Surfing' column at the fourth position (index 7) \n",
    "cols = list(df.columns)\n",
    "cols.remove('Surfing')\n",
    "cols.insert(7, 'Surfing')\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the 'Year' Column\n",
    "\n",
    "In this section, we'll handle the missing and inconsistent values in the 'Year' column to ensure the data is in the correct format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 6757 entries, 0 to 7041\n",
      "Series name: Year\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "6756 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 105.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the 'Year' column in the dataframe\n",
    "df['Year'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Surfing</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Country_cleaned</th>\n",
       "      <th>Fatal Y/N cleaned</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Reported 08-Jan-2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>False</td>\n",
       "      <td>Kerry Daniel</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>No attack, shark made a threat display</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Liquid Vision 1/8/2017</td>\n",
       "      <td>2017.01.08.R-KerryDaniel.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>6142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  Year     Type    Country       State Location  \\\n",
       "896  Reported 08-Jan-2017   NaN  Invalid  AUSTRALIA  Queensland      NaN   \n",
       "\n",
       "         Activity  Surfing          Name Sex Age  \\\n",
       "896  Spearfishing    False  Kerry Daniel   M  35   \n",
       "\n",
       "                                     Injury Fatal Y/N Time    Species   \\\n",
       "896  No attack, shark made a threat display       NaN  NaN  Bull shark   \n",
       "\n",
       "                     Source                           pdf  \\\n",
       "896  Liquid Vision 1/8/2017  2017.01.08.R-KerryDaniel.pdf   \n",
       "\n",
       "                                          href formula  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                  href   Case Number  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...  2017.01.08.R   \n",
       "\n",
       "    Case Number.1  original order Unnamed: 21 Unnamed: 22 Country_cleaned  \\\n",
       "896  2017.01.08.R          6142.0         NaN         NaN       Australia   \n",
       "\n",
       "    Fatal Y/N cleaned  Death  \n",
       "896               NAN    NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the null values in the Year column\n",
    "df[df['Year'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Surfing</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal Y/N</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Country_cleaned</th>\n",
       "      <th>Fatal Y/N cleaned</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>Reported 08-Jan-2017</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>False</td>\n",
       "      <td>Kerry Daniel</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>No attack, shark made a threat display</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bull shark</td>\n",
       "      <td>Liquid Vision 1/8/2017</td>\n",
       "      <td>2017.01.08.R-KerryDaniel.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>2017.01.08.R</td>\n",
       "      <td>6142.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date    Year     Type    Country       State Location  \\\n",
       "896  Reported 08-Jan-2017  2017.0  Invalid  AUSTRALIA  Queensland      NaN   \n",
       "\n",
       "         Activity  Surfing          Name Sex Age  \\\n",
       "896  Spearfishing    False  Kerry Daniel   M  35   \n",
       "\n",
       "                                     Injury Fatal Y/N Time    Species   \\\n",
       "896  No attack, shark made a threat display       NaN  NaN  Bull shark   \n",
       "\n",
       "                     Source                           pdf  \\\n",
       "896  Liquid Vision 1/8/2017  2017.01.08.R-KerryDaniel.pdf   \n",
       "\n",
       "                                          href formula  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                  href   Case Number  \\\n",
       "896  http://sharkattackfile.net/spreadsheets/pdf_di...  2017.01.08.R   \n",
       "\n",
       "    Case Number.1  original order Unnamed: 21 Unnamed: 22 Country_cleaned  \\\n",
       "896  2017.01.08.R          6142.0         NaN         NaN       Australia   \n",
       "\n",
       "    Fatal Y/N cleaned  Death  \n",
       "896               NAN    NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the two null entries in the 'Year' column by importing the year from the 'Date' column\n",
    "\n",
    "import re\n",
    "\n",
    "# Extract the year (4 digits) from the 'Date' column for row 896\n",
    "year_896 = re.search(r'\\d{4}', df.loc[896, 'Date']).group()\n",
    "\n",
    "# Update the 'Year' column with the extracted year for row 896\n",
    "df.loc[896, 'Year'] = float(year_896)\n",
    "\n",
    "df.loc[[896]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Year' column to integer data type for numerical operations\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "# Print the data type to verify the conversion was successful\n",
    "print(df['Year'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2025, 2024, 2026, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016,\n",
       "       2015, 2014, 2013, 2012, 2011, 2010, 2009, 2008, 2007, 2006, 2005,\n",
       "       2004, 2003, 2002, 2001, 2000, 1999, 1998, 1997, 1996, 1995, 1984,\n",
       "       1994, 1993, 1992, 1991, 1990, 1989, 1969, 1988, 1987, 1986, 1985,\n",
       "       1983, 1982, 1981, 1980, 1979, 1978, 1977, 1976, 1975, 1974, 1973,\n",
       "       1972, 1971, 1970, 1968, 1967, 1966, 1965, 1964, 1963, 1962, 1961,\n",
       "       1960, 1959, 1958, 1957, 1956, 1955, 1954, 1953, 1952, 1951, 1950,\n",
       "       1949, 1948, 1848, 1947, 1946, 1945, 1944, 1943, 1942, 1941, 1940,\n",
       "       1939, 1938, 1937, 1936, 1935, 1934, 1933, 1932, 1931, 1930, 1929,\n",
       "       1928, 1927, 1926, 1925, 1924, 1923, 1922, 1921, 1920, 1919, 1918,\n",
       "       1917, 1916, 1915, 1914, 1913, 1912, 1911, 1910, 1909, 1908, 1907,\n",
       "       1906, 1905, 1904, 1903, 1902, 1901, 1900, 1899, 1898, 1897, 1896,\n",
       "       1895, 1894, 1893, 1892, 1891, 1890, 1889, 1888, 1887, 1886, 1885,\n",
       "       1884, 1883, 1882, 1881, 1880, 1879, 1878, 1877, 1876, 1875, 1874,\n",
       "       1873, 1872, 1871, 1870, 1869, 1868, 1867, 1866, 1865, 1864, 1863,\n",
       "       1862, 1861, 1860, 1859, 1858, 1857, 1856, 1855, 1853, 1852, 1851,\n",
       "       1850, 1849, 1847, 1846, 1845, 1844, 1842, 1841, 1840, 1839, 1837,\n",
       "       1836, 1835, 1834, 1832, 1831, 1830, 1829, 1828, 1827, 1826, 1825,\n",
       "       1823, 1822, 1819, 1818, 1817, 1816, 1810, 1808, 1807, 1805, 1804,\n",
       "       1803, 1802, 1800, 1791, 1788, 1786, 1784, 1783, 1780, 1779, 1776,\n",
       "       1771, 1767, 1764, 1753, 1751, 1749, 1755, 1748, 1738, 1733, 1721,\n",
       "       1703, 1700, 1642, 1691, 1640, 1637, 1617, 1595, 1554, 1543, 1518,\n",
       "       1500, 1000,    5,    0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all unique values from the 'Year' column in the dataframe\n",
    "# Quick overview to check if there is any recent missing year\n",
    "df['Year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the 'Date' Column\n",
    "\n",
    "In this section, we'll handle the missing and inconsistent values in the 'Date' column to ensure the data is in the correct format for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1957                    9\n",
       "1958                    7\n",
       "1956                    6\n",
       "1941                    6\n",
       "No date                 6\n",
       "28-Jul-1995             5\n",
       "12-Apr-2001             5\n",
       "2024-07-04 00:00:00     5\n",
       "05-Oct-2003             5\n",
       "1970s                   5\n",
       "Aug-1956                5\n",
       "1955                    5\n",
       "1954                    5\n",
       "1942                    5\n",
       "No date, Before 1963    5\n",
       "15-Apr-2018             4\n",
       "1960                    4\n",
       "1960s                   4\n",
       "1959                    4\n",
       "Before 1906             4\n",
       "27-Dec-2008             4\n",
       "29-Apr-2017             4\n",
       "09-Jan-2010             4\n",
       "14-Jun-2012             4\n",
       "23-Jan-1970             4\n",
       "27-Jul-1952             4\n",
       "1952                    4\n",
       "1950                    4\n",
       "1949                    4\n",
       "1945                    4\n",
       "28-Dec-2014             4\n",
       "04 Jul-2023             4\n",
       "Reported 10-Oct-1906    4\n",
       "09-Jul-1994             4\n",
       "20-Sep-2015             4\n",
       "Before 1958             4\n",
       "02-Sep-2012             3\n",
       "30-Sep-2007             3\n",
       "11-Aug-1997             3\n",
       "2025-02-22 00:00:00     3\n",
       "16-May-1998             3\n",
       "27-Jul-2021             3\n",
       "27-Sep-2002             3\n",
       "09-Dec-1994             3\n",
       "23-Oct-2017             3\n",
       "27-Aug-2014             3\n",
       "14-Sep-2003             3\n",
       "01-Jun-2014             3\n",
       "23-Oct-2018             3\n",
       "31-Oct-2003             3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify and show the top 50 most common dates in the 'Date' column\n",
    "# For quick overview of inconsistent formatting \n",
    "df['Date'].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " THE MOST COMMON TEXT PATTERNS OF 'DATE' COLUMN ARE:\n",
      " 0\n",
      "Jul         657\n",
      "Aug         591\n",
      "Sep         514\n",
      "Reported    512\n",
      "Jan         494\n",
      "Jun         471\n",
      "Oct         438\n",
      "Apr         435\n",
      "Dec         430\n",
      "Mar         415\n",
      "May         400\n",
      "Nov         396\n",
      "Feb         378\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Extract date patterns from the 'Date' column using regex\n",
    "# The regex pattern looks for:\n",
    "# - 4-digit years (e.g., 2023)\n",
    "# - Numbers with ordinal suffixes (e.g., 1st, 2nd, 3rd, 4th)\n",
    "# - Date ranges with hyphens (e.g., 1-2, 10-15)\n",
    "# - Year ranges (e.g., 2020-2022)\n",
    "# - Month names or other text (e.g., January, Feb)\n",
    "date_patterns = df['Date'].astype(str).str.extract(r'(\\d{4}|\\d{1,2}(?:st|nd|rd|th)|\\d{1,2}-\\d{1,2}|\\d{4}-\\d{4}|[A-Za-z]+)')\n",
    "\n",
    "# Display the 13 most common date patterns found in the dataset\n",
    "print(f\"\\n THE MOST COMMON TEXT PATTERNS OF 'DATE' COLUMN ARE:\\n\", date_patterns[0].value_counts().head(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118     Reported 02 Nov-2023\n",
      "154     Reported 14 Jul-2023\n",
      "163    Reported 14-June 2023\n",
      "277     Reported 27-Apr-2022\n",
      "298     Reported 10-Feb-2022\n",
      "312     Reported 06-Dec-2021\n",
      "351     Reported 11-Jul-2021\n",
      "505     Reported 14-Mar-2020\n",
      "510     Reported 30-Jan-2020\n",
      "549     Reported 04-Oct-2019\n",
      "577     Reported 17-Jul-2019\n",
      "591     Reported 06-Jun-2019\n",
      "606     Reported 27-Apr-2019\n",
      "656     Reported 16-Oct-2018\n",
      "674     Reported 28-Aug-2018\n",
      "690     Reported 16-Jul-2018\n",
      "697    Reported 09-Jul-2018.\n",
      "719     Reported 30-Apr-2018\n",
      "734     Reported 10-Apr-2018\n",
      "764     Reported 25-Nov-2017\n",
      "Name: Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect entries containing the word 'Reported'\n",
    "# Filter the dataframe to only include rows where the 'Date' column contains the word \"Reported\" \n",
    "df_reported = df[df['Date'].astype(str).str.contains(\"Reported\", case=False)]\n",
    "print(df_reported['Date'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping various month name formats (including abbreviations and different languages) to standardized 3-letter format\n",
    "month_mapping = {\n",
    "    'jan': 'Jan', 'january': 'Jan',\n",
    "    'feb': 'Feb', 'february': 'Feb', 'fev': 'Feb',\n",
    "    'mar': 'Mar', 'march': 'Mar',\n",
    "    'apr': 'Apr', 'april': 'Apr', 'abr': 'Apr',\n",
    "    'may': 'May',\n",
    "    'jun': 'Jun', 'june': 'Jun',\n",
    "    'jul': 'Jul', 'july': 'Jul',\n",
    "    'aug': 'Aug', 'august': 'Aug', 'ago': 'Aug',\n",
    "    'sep': 'Sep', 'september': 'Sep', 'set': 'Sep',\n",
    "    'oct': 'Oct', 'october': 'Oct', 'out': 'Oct',\n",
    "    'nov': 'Nov', 'november': 'Nov',\n",
    "    'dec': 'Dec', 'december': 'Dec', 'dez': 'Dec'\n",
    "}\n",
    "\n",
    "## Create a regex pattern by joining all month keys with '|' (OR operator)\n",
    "all_month_patterns = '|'.join(month_mapping.keys())\n",
    "\n",
    "# Extract month from 'Date' column using regex pattern:\n",
    "# 1. Convert Date column to string\n",
    "# 2. Extract month name using case-insensitive regex (?i)\n",
    "# 3. Convert extracted month to lowercase\n",
    "# 4. Map to standardized format using the month_mapping dictionary\n",
    "df['Month'] = df['Date'].astype(str).str.extract(f'(?i)({all_month_patterns})', expand=False).str.lower().map(month_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Month\n",
       "Jul    753\n",
       "Aug    652\n",
       "Sep    569\n",
       "Jan    546\n",
       "Jun    527\n",
       "Oct    481\n",
       "Apr    477\n",
       "Dec    475\n",
       "Mar    446\n",
       "May    434\n",
       "Nov    430\n",
       "Feb    411\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse the new column 'Month' to understand if the value counts coincide with the date-paterns\n",
    "df['Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 6757 entries, 0 to 7041\n",
      "Series name: Month\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "6201 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 363.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the newly created 'Month' column\n",
    "df.Month.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>1952</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>Ca 1200-1500 A.D.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6759</th>\n",
       "      <td>1850</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6914</th>\n",
       "      <td>Ca. 336.B.C..</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>No date, Before  1975</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2025-02-27 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>1943</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6927</th>\n",
       "      <td>Before 1934</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>1954</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>1950s</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>1985</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7006</th>\n",
       "      <td>1940 - 1950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>1984</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5886</th>\n",
       "      <td>1926</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>1943</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>1953</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6935</th>\n",
       "      <td>Before 1900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>Summer of 1981</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2024-07-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>Ca. 1950</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>1958</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>1920 -1923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>1642</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>1941</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2024-12-29 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>Circa 1862</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>1907</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6916</th>\n",
       "      <td>Ca. 725 B.C.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>1961</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>1971</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date Month\n",
       "5149                   1952   NaN\n",
       "6909      Ca 1200-1500 A.D.   NaN\n",
       "6759                   1850   NaN\n",
       "6914          Ca. 336.B.C..   NaN\n",
       "6966  No date, Before  1975   NaN\n",
       "32      2025-02-27 00:00:00   NaN\n",
       "5413                   1943   NaN\n",
       "6927            Before 1934   NaN\n",
       "5081                   1954   NaN\n",
       "6954                  1950s   NaN\n",
       "3583                   1985   NaN\n",
       "7006            1940 - 1950   NaN\n",
       "3623                   1984   NaN\n",
       "5886                   1926   NaN\n",
       "5416                   1943   NaN\n",
       "5118                   1953   NaN\n",
       "6935            Before 1900   NaN\n",
       "3765         Summer of 1981   NaN\n",
       "72      2024-07-04 00:00:00   NaN\n",
       "5223               Ca. 1950   NaN\n",
       "4899                   1958   NaN\n",
       "7022             1920 -1923   NaN\n",
       "6902                   1642   NaN\n",
       "5481                   1941   NaN\n",
       "49      2024-12-29 00:00:00   NaN\n",
       "6704             Circa 1862   NaN\n",
       "6192                   1907   NaN\n",
       "6916           Ca. 725 B.C.   NaN\n",
       "4663                   1961   NaN\n",
       "4097                   1971   NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect all null entries in the 'Month' column \n",
    "# df[df['Month'].isna()] \n",
    "\n",
    "#Inspect null values in the 'Month' column compared to the values in 'Date' column\n",
    "# print(df[df['Month'].isnull()][['Date', 'Month']].head(20))\n",
    "# print(df[df['Month'].isnull()][['Date', 'Month']].tail(20))\n",
    "df[df['Month'].isnull()][['Date', 'Month']].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Date Month\n",
      "19  2025-06-11 00:00:00   NaN\n",
      "21  2025-05-29 00:00:00   NaN\n",
      "22  2025-05-26 00:00:00   NaN\n",
      "23  2025-05-15 00:00:00   NaN\n",
      "24  2025-05-08 00:00:00   NaN\n",
      "25  2025-04-21 00:00:00   NaN\n",
      "26  2025-04-20 00:00:00   NaN\n",
      "27  2025-04-19 00:00:00   NaN\n",
      "28  2025-04-12 00:00:00   NaN\n",
      "29  2025-03-26 00:00:00   NaN\n",
      "30  2025-03-10 00:00:00   NaN\n",
      "31  2025-03-07 00:00:00   NaN\n",
      "32  2025-02-27 00:00:00   NaN\n",
      "34  2025-02-22 00:00:00   NaN\n",
      "35  2025-02-22 00:00:00   NaN\n",
      "36  2025-02-22 00:00:00   NaN\n",
      "37  2025-02-10 00:00:00   NaN\n",
      "38  2025-02-10 00:00:00   NaN\n",
      "40  2025-02-03 00:00:00   NaN\n",
      "41  2025-01-23 00:00:00   NaN\n",
      "Total found: 67\n"
     ]
    }
   ],
   "source": [
    "# Create a boolean mask to filter rows where 'Date' column matches the format 'YYYY-MM-DD HH:MM:SS'\n",
    "mask = df['Date'].astype(str).str.match(r'^\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}$')\n",
    "\n",
    "# Filter the dataframe to keep only rows that match the date format pattern\n",
    "# and select only the 'Date' and 'Month' columns\n",
    "df_filtered = df.loc[mask, ['Date', 'Month']]\n",
    "\n",
    "# Display the first 20 rows of the filtered dataframe\n",
    "print(df_filtered.head(20)) \n",
    "\n",
    "# Print the total number of rows that match the date format pattern\n",
    "print(f\"Total found: {len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping numeric month representations to abbreviated month names\n",
    "numeric_month_mapping = {\n",
    "    '01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr', '05': 'May', '06': 'Jun',\n",
    "    '07': 'Jul', '08': 'Aug', '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'\n",
    "}\n",
    "\n",
    "# Create a boolean mask for rows where 'Month' column contains NaN values\n",
    "nan_mask = df['Month'].isna()\n",
    "\n",
    "# For rows with missing month values, extract the month part (MM) from the 'Date' column\n",
    "# using regex pattern that matches YYYY-MM-DD format\n",
    "extracted_numeric_months = df.loc[nan_mask, 'Date'].astype(str).str.extract(r'\\d{4}-(\\d{2})-\\d{2}', expand=False)\n",
    "\n",
    "# Replace NaN values in 'Month' column with the corresponding month abbreviations\n",
    "df.loc[nan_mask, 'Month'] = extracted_numeric_months.map(numeric_month_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "Jul    763\n",
      "Aug    654\n",
      "Sep    572\n",
      "Jan    552\n",
      "Jun    534\n",
      "Oct    485\n",
      "Apr    485\n",
      "Dec    481\n",
      "Mar    449\n",
      "May    442\n",
      "Nov    433\n",
      "Feb    418\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "<class 'pandas.core.series.Series'>\n",
      "Index: 6757 entries, 0 to 7041\n",
      "Series name: Month\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "6268 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 363.6+ KB\n",
      "None \n",
      "\n",
      "['Aug' 'Jul' 'Jun' 'May' 'Apr' 'Mar' 'Feb' 'Jan' 'Dec' 'Nov' 'Oct' 'Sep'\n",
      " nan]\n"
     ]
    }
   ],
   "source": [
    "# Reinspect the 'Month' to confirm extraction of values formatted as 'YYYY-MM-DD HH:MM:SS' in the 'Date' column\n",
    "print(df['Month'].value_counts(), '\\n')\n",
    "print(df['Month'].info(), '\\n')\n",
    "print(df['Month'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relocate 'Month' column at the second position (index 1) \n",
    "cols = list(df.columns)\n",
    "cols.remove('Month')\n",
    "cols.insert(1, 'Month')\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
